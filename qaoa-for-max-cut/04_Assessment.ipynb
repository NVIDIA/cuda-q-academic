{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e406cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dbe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for Google Colab. You can ignore this cell if you have cuda-q set up.\n",
    "# Run this portion of the notebook in a CPU runtime\n",
    "# Uncomment the line below and execute the cell to install cuda-q\n",
    "# !pip install cudaq\n",
    "\n",
    "#!wget -q https://github.com/nvidia/cuda-q-academic/archive/refs/heads/main.zip\n",
    "#!unzip -q main.zip\n",
    "#!mv cuda-q-academic-main/qaoa-for-max-cut/images ./images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f6e3e-e55f-4b5c-80cb-f8979bba94e0",
   "metadata": {},
   "source": [
    "# Divide-and-Conquer Implementation of QAOA\n",
    "## Lab 4 Assessment\n",
    "$\n",
    "\\renewcommand{\\ket}[1]{|{#1}\\rangle}\n",
    "\\renewcommand{\\bra}[1]{\\langle{#1}|}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bc9e4",
   "metadata": {},
   "source": [
    "## 4.1 Lab Description\n",
    "\n",
    "Congratulations on making it this far! We hope you enjoyed conquering a large max cut problem while picking up a few skills along the way.\n",
    "\n",
    "For this assessment, the challenge is to adapt the code that we have created for the max cut problem and apply it to the weighted max cut problem. As we described at the end of [Lab 3](3_Recursive-divide-and-conquer.ipynb), there are many options for coding QAOA that can improve performance and accuracy. We encourage you to experiment with at least one of these to achieve a max cut approximation of a weighted version of the example graph from [Lab 2](2_One-level-divide-and-conquer-QAOA.ipynb). We chose this moderately sized graph for the sake of time, but we do give you the option to experiment with other graphs.\n",
    "\n",
    "The learning objectives of this tutorial are:\n",
    "* Execute the QAOA algorithm to find approximate max cuts of a given graph using CUDA Quantum\n",
    "* Understand the limitations of the QAOA algorithm for solving max cut in the NISQ era \n",
    "* Make adjustments to the divide-and-conquer QAOA algorithm through selection of initial parameter values, increased layers, choice of optimizer, or other methods\n",
    "* Simulate quantum circuits in parallel on multiple GPUs to speed up overall run time using CUDA Quantum\n",
    "\n",
    "Let's get started!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3721df5",
   "metadata": {},
   "source": [
    "## 4.2 Weighted Max Cut Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b602e0",
   "metadata": {},
   "source": [
    "\n",
    "The weighted max cut problem is a variation of the max cut problem. The weighted version of the problem aims to identify a partition of a graph's nodes into two sets which maximizes the sum of the weights of the edges between the two sets. We continue with the notation established in the previous labs. The only difference between this problem and the max cut problem from before is that we now want to maximize: \n",
    "$$\\sum_{\\substack{(u,v)\\in E\\\\ u\\in V_0, v\\in V_1}}w_{u,v},$$\n",
    "\n",
    "where $w_{u,v}$ is the weight of the edge connecting vertex $u$ to $v$.  As before $E$ is the set of the edges of the graph, and $V_0$ and $V_1$ define a partition of the vertices of the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458502bb",
   "metadata": {},
   "source": [
    "## 4.3 Adapting our code from the previous labs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a462183",
   "metadata": {},
   "source": [
    "We can use most of the code that we've already developed. There are a few changes that need to be made at the divide, conquer, and merge stages of the QAOA divide-and-conquer algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for Google Colab. You can ignore this cell if you have cuda-q set up.\n",
    "# Run this portion of the notebook in a GPU runtime \n",
    "# Uncomment the line below and execute the cell to install cuda-q\n",
    "# !pip install cudaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c4006e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary packages\n",
    "import networkx as nx\n",
    "from networkx import algorithms\n",
    "from networkx.algorithms import community\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "from cudaq.qis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173a9ba",
   "metadata": {},
   "source": [
    "### 4.3.1 Divide\n",
    "\n",
    "Since we now have a weighted graph, we will want to take these weights into account when identifying the subgraph partition.  We've made the adjustment to the `subgraph_partition` function below. This may produce a different partitioning of our weighted graph than if we had ignored the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe4009ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgraphpartition(G,n, name, globalGraph):\n",
    "    \"\"\"Divide the graph up into at most n subgraphs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G: networkX.Graph \n",
    "        Graph that we want to subdivivde which lives inside of or is equatl to globalGraph\n",
    "    n : int\n",
    "        n is the maximum number of subgraphs in the partition\n",
    "    name : str\n",
    "        prefix for the graphs (in our case we'll use 'Global')\n",
    "    globalGraph: networkX.Graph\n",
    "        original problem graph\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict of str : networkX.Graph\n",
    "        Dictionary of networkX graphs with a string as the key\n",
    "    \"\"\"\n",
    "    greedy_partition = community.greedy_modularity_communities(G, weight='weight', resolution=1.1, cutoff=1, best_n=n)\n",
    "    number_of_subgraphs = len(greedy_partition)\n",
    "\n",
    "    graph_dictionary = {}\n",
    "    graph_names=[]\n",
    "    for i in range(number_of_subgraphs):\n",
    "        subgraphname=name+':'+str(i)\n",
    "        graph_names.append(subgraphname)\n",
    "\n",
    "    for i in range(number_of_subgraphs):\n",
    "        nodelist = sorted(list(greedy_partition[i]))\n",
    "        graph_dictionary[graph_names[i]] = nx.subgraph(globalGraph, nodelist)\n",
    "     \n",
    "    return(graph_dictionary) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7744a",
   "metadata": {},
   "source": [
    "### 4.3.2 Conquer\n",
    "\n",
    "To adapt the dividie-and-conquer QAOA algorithm to handle a weighted graph, we will need to change the Hamiltonian function.  We refer you to section 1.4.1 of [Lab 1](01_Max-Cut-with-QAOA.ipynb) to derive the Hamiltonian for the weighted max cut problem.  Below we've copied and adapted the code from the `hamiltonian_max_cut` function from the previous labs by adding a new function argument for the weights.  You'll need to fix the indicated line of code to take into account the weights of the edges.  \n",
    "\n",
    "HINT: You'll need to consider the weight of each edge, which we have computed for you in the `edge_weight` variable.\n",
    "\n",
    "**Exercise:** Edit the line commented with `###FIX_ME###`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff41e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "\n",
    "def hamiltonian_max_cut(sources : List[int], targets : List[int], weights : List[float]): \n",
    "    \"\"\"Hamiltonian for finding the max cut for the graph  with edges defined by the pairs generated by source and target edges\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    sources: List[int] \n",
    "        list of the source vertices for edges in the graph\n",
    "    targets: List[int]\n",
    "        list of the target vertices for the edges in the graph\n",
    "    weights : List[float]\n",
    "        list of the weight of the edge determined by the source and target with the same index\n",
    "    Returns\n",
    "    -------\n",
    "    cudaq.SpinOperator\n",
    "        Hamiltonian for finding the max cut of the graph defined by the given edges\n",
    "    \"\"\"\n",
    "    hamiltonian = 0\n",
    "    # Since our vertices may not be a list from 0 to n, or may not even be integers,\n",
    "    \n",
    "    for i in range(len(sources)):\n",
    "        # Add a term to the Hamiltonian for the edge (u,v)\n",
    "        qubitu = sources[i]\n",
    "        qubitv = targets[i]\n",
    "        edge_weight = weights[i]\n",
    "        hamiltonian += ##FIX_ME## \n",
    "    \n",
    "    return hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420624a",
   "metadata": {},
   "source": [
    "Since we've changed the function arguments for the `hamiltonian_max_cut` function, we've edited the code from the previous labs that calls this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36167f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_parameters(G, layer_count, seed):\n",
    "    \"\"\"Function for finding the optimal parameters of QAOA for the max cut of a graph\n",
    "    Parameters\n",
    "    ----------\n",
    "    G: networkX graph \n",
    "        Problem graph whose max cut we aim to find\n",
    "    layer_count : int \n",
    "        Number of layers in the QAOA circuit\n",
    "    seed : int\n",
    "        Random seed for reproducibility of results\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list[float]\n",
    "        Optimal parameters for the QAOA applied to the given graph G\n",
    "    \"\"\"\n",
    "    parameter_count: int = 2 * layer_count\n",
    "\n",
    "    # Problem parameters\n",
    "    nodes = sorted(list(nx.nodes(G)))\n",
    "    qubit_src = []\n",
    "    qubit_tgt = []\n",
    "    weights = []\n",
    "    for u, v in nx.edges(G):\n",
    "        # We can use the index() command to read out the qubits associated with the vertex u and v.\n",
    "        qubit_src.append(nodes.index(u))\n",
    "        qubit_tgt.append(nodes.index(v))\n",
    "        weights.append(G.edges[u,v]['weight'])                                           \n",
    "    # The number of qubits we'll need is the same as the number of vertices in our graph\n",
    "    qubit_count : int = len(nodes)\n",
    "    # Each layer of the QAOA kernel contains 2 parameters\n",
    "    parameter_count : int = 2*layer_count\n",
    "    \n",
    "    # Specify the optimizer and its initial parameters. \n",
    "    optimizer = cudaq.optimizers.COBYLA()\n",
    "    np.random.seed(seed)\n",
    "    cudaq.set_random_seed(seed)\n",
    "    optimizer.initial_parameters = np.random.uniform(-np.pi, np.pi,\n",
    "                                                     parameter_count)   \n",
    "\n",
    "    # Pass the kernel, spin operator, and optimizer to `cudaq.vqe`.\n",
    "    optimal_expectation, optimal_parameters = cudaq.vqe(\n",
    "        kernel=kernel_qaoa,\n",
    "        spin_operator=hamiltonian_max_cut(qubit_src, qubit_tgt, weights),\n",
    "        argument_mapper=lambda parameter_vector: (qubit_count, layer_count, qubit_src, qubit_tgt, parameter_vector),\n",
    "        optimizer=optimizer,\n",
    "        parameter_count=parameter_count)\n",
    "\n",
    "    return optimal_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba4faf",
   "metadata": {},
   "source": [
    "### 4.3.3 Merge\n",
    "\n",
    "The weights of the edges between subgraphs will impact the merger stage of the algorithm as well.  \n",
    "\n",
    "**Exercise:** Edit the code block by replacing `FIX_ME` with the appropriate values to compute the penalties associated with each edge of the merger graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exercise\n",
    "# Compute the penalties for edges in the supplied mergerGraph\n",
    "# for the subgraph partitioning of graph G\n",
    "def merger_graph_penalties(mergerGraph, subgraph_dictionary, G):\n",
    "    \"\"\"Compute penalties for the edges in the mergerGraph and add them\n",
    "    as edge attributes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mergerGraph : networkX.Graph \n",
    "        Graph of connections between vertices in distinct subgraphs of G\n",
    "    subgraph_dictionary : dict of networkX graph with str as keys \n",
    "        subgraphs of G that are represented as nodes in the mergerGraph\n",
    "    G : networkX.Graph\n",
    "        graph whose vertices has an attribute 'color'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    networkX.Graph\n",
    "        Merger graph containing penalties\n",
    "    \"\"\" \n",
    "    nx.set_edge_attributes(mergerGraph, int(0), 'penalty')\n",
    "    for i, j in mergerGraph.edges():\n",
    "        penalty_ij = 0\n",
    "        for u in nx.nodes(subgraph_dictionary[i]):\n",
    "            for neighbor_u in nx.all_neighbors(G, u):\n",
    "                if neighbor_u in nx.nodes(subgraph_dictionary[j]):\n",
    "                    if G.nodes[u]['color'] != G.nodes[neighbor_u]['color']:\n",
    "                        penalty_ij += ### FIX_ME\n",
    "                    else:\n",
    "                        penalty_ij += ### FIX_ME\n",
    "        mergerGraph[i][j]['penalty'] = penalty_ij\n",
    "    return mergerGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f53c2e",
   "metadata": {},
   "source": [
    "Finally, since our cut value now depends on the weight of the edges, we will need to edit the `cutvalue` function that comptues the cut of the graph based on the coloring of the nodes.\n",
    "\n",
    "**Exercise:** Edit the `FIX_ME` line of the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b9f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "def cutvalue(G):\n",
    "    \"\"\"Returns the cut value of G based on the coloring of the nodes of G\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G: networkX.Graph \n",
    "        Graph with weighted edges and with binary value colors assigned to the vertices \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        cut value of the graph determined by the vertex colors and edge weights\n",
    "    \"\"\"   \n",
    "    cut = 0\n",
    "    for u, v in G.edges():\n",
    "        if G.nodes[u]['color'] != G.nodes[v]['color']: \n",
    "            cut+=##FIX_ME\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dd281",
   "metadata": {},
   "source": [
    "## 4.4 Weighted Max Cut using a modified Divide-and-Conquer QAOA\n",
    "\n",
    "If you have not already done so, download the Example-04.py from the repository and save it to your working directory. Add the modifications that were made in the exercises above to the [Example-04.py](https://github.com/NVIDIA/cuda-q-academic/blob/main/qaoa-for-max-cut/Example-04.py) which calls up the example graph from [Lab 2](2_One-level-divide-and-conquer-QAOA.ipynb) with random weights assigned to the vertices. In particular fill in your code between the lines `# Edit the code above` and `# Edit the code below` for the functions: `hamiltonian_max_cut`, `merger_graph_penalties`, and `cutvalue`.  Make sure to save the file.  Run the MPI call below to see how the algorithm performs.  You may notice the results are not competitive with the classical methods, as is.  \n",
    "\n",
    "For the assessment, make modifications to the Example-04.py to improve performance by making some adjustments as discussed at the end of [Lab 3](3_Recursive-divide-and-conquer.ipynb).  Here are a few recommendations:\n",
    "\n",
    "* Modify the layer count for the QAOA max cut (line 822) and the QAOA merger calls (line 505).\n",
    "* Try different seeds to generate different initial parameters for the optimizer for the QAOA for max cut (line 823) and for the merger stage (line 507).  Better yet, replace the random intitial parameters of the optimizer with the optimal parameters found in earlier runs of the algorithm. We've added a print command to [Example-04.py](Example-04.py) to view the optimal parameters of the max cut QAOA calls at each stage.  For instance try initializing the optimzer with ( `[-1.8964004059756836, 1.0646218219788401]*layer_count`).\n",
    "* Swap out the COYBLA optimizer with another [optimizer supported by CUDA Quantum](https://nvidia.github.io/cuda-quantum/latest/api/languages/python_api.html#cudaq.optimizers.optimizer) on line 184 and line 520.  Depending on your choice of optimizer you may need to add in a variable for the gradient and make adjustments to the `vqe` calls (lines 191 and 526). \n",
    "* Replace the QAOA kernel with a multi-angle kernel.  In addition to editing the `kernel_qaoa` function (line 113), you will need to adjust the parameter_count variables (lines 181 and 340) accordingly.\n",
    "\n",
    "Feel free to experiment with one or all of these suggestions, or try out your own ideas!  You can also play around with different graph instances by editing the lines 709 to 750. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e3d75",
   "metadata": {},
   "source": [
    "**Important** Before proceeding, you will need to switch to a runtime with access to a GPU.  If you do restart your kernel, make sure to reload the packages below.  If you are running on Google Colab and switch to a GPU runtime, you'll need to reinstall CUDA-Q by commenting out the indicated code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497318c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for Google Colab. You can ignore this cell if you already have cuda-q set up and are working in a GPU runtime\n",
    "# with all the necessary files\n",
    "# Run this cell in a GPU runtime\n",
    "\n",
    "#!pip install cudaq\n",
    "\n",
    "#!wget -q -O Example-04.py https://raw.githubusercontent.com/NVIDIA/cuda-q-academic/main/qaoa-for-max-cut/Example-04.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Execute this cell to reload the necessary packages\n",
    "import networkx as nx\n",
    "from networkx import algorithms\n",
    "from networkx.algorithms import community\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "from cudaq.qis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61327d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Execute this cell to install mpi4py if necessary\n",
    "%pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fb85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MPI call\n",
    "print(sys.executable)\n",
    "python_path = sys.executable\n",
    "!mpiexec -np 4 --oversubscribe --allow-run-as-root {python_path} Example-04.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a5b68",
   "metadata": {},
   "source": [
    "## 4.5 Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b67f41",
   "metadata": {},
   "source": [
    "To learn more about CUDA Quantum, check out our online [tutorials](https://nvidia.github.io/cuda-quantum/latest/using/tutorials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231f912",
   "metadata": {},
   "source": [
    "![](images/nvidia-logo.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
