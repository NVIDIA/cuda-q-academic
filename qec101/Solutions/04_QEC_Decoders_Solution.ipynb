{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b32b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33ec99-e8e6-4a88-b4ea-bcf1e8bbb0df",
   "metadata": {},
   "source": [
    "# QEC 101\n",
    "## Lab 4: Decoders\n",
    "\n",
    "\n",
    "QEC is only effective if the codes utilized to flag errors can be interpreted to identify the errors to be fixed. This is the job of a decoder.  Decoding is one of the most challenging yet critical aspects of QEC and finding good decoders is a major researcher objective in the field.\n",
    "\n",
    "This lab introduces the basic concepts of decoding and frames why the problem is so difficult.  In the later sections, you will then work through a number of exercises to implement a naive \"brute force\" decoder, train an AI decoder, and explore how GPUs can power advanced decoding algorithms like belief propagation with ordered statistics decoding. \n",
    "\n",
    "\n",
    "**Prerequisites:** This is the 4th lab in the QEC series. If you are not familiar with the basics of classical or quantum error correction (EC), please complete [\"The Basics of Classical and Quantum Error Correction\"](https://github.com/NVIDIA/cuda-q-academic/blob/main/qec101/01_QEC_Intro.ipynb) first.  It is also helpful to have completed [\"Stabilizers, the Shor Code, and the Steane Code\"](https://github.com/NVIDIA/cuda-q-academic/blob/main/qec101/02_QEC_Stabilizers.ipynb) in which stabilizers and syndromes are introduced in detail. This notebook also walks you through building a Steane code implementation in CUDA-Q which is used again in this lab. \n",
    "\n",
    "The list below outlines what you'll be doing in each section of this lab:\n",
    "\n",
    "* **4.1** Understand what decoding is, why it is important, and what makes it so difficult\n",
    "* **4.2** Explore Pauli frames and error tracking\n",
    "* **4.3** Code a naive brute force decoder for the Steane Code\n",
    "* **4.4** Train an AI decoder for the Steane Code\n",
    "* **4.5** Experiment with NVIDIA's accelerated belief propagation decoder.\n",
    "\n",
    "Terminology and notation you'll use:\n",
    "* decoders, decoding window, Pauli frames\n",
    "* most likely error decoding\n",
    "* AI decoding\n",
    "* Belief propagation and ordered statistics decoding\n",
    "\n",
    "ðŸ’» Just a heads-up: This notebook is designed to be run on an environment with a GPU. If you don't have access to a GPU, feel free to read through the cells and explore the content without executing them. Enjoy learning! â­\n",
    "\n",
    "To get started, run the cells below to install the prerequisite libraries and then restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d5510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instructions for Google Colab. You can ignore this cell if you have cuda-q set up \n",
    "# Run this notebook in a GPU runtime\n",
    "# Uncomment the lines below and execute the cell to install cuda-q\n",
    "\n",
    "#!pip install cudaq\n",
    "\n",
    "\n",
    "#!wget -q https://github.com/nvidia/cuda-q-academic/archive/refs/heads/main.zip\n",
    "#!unzip -q main.zip\n",
    "#!mv cuda-q-academic-main/qec101/Images ./Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3fc629-1a82-4eec-b946-1f3014d749ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools not found, installing. Please restart your kernel after this is done.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/cudaq/.local/lib/python3.12/site-packages (25.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/cudaq/.local/lib/python3.12/site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch) (68.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/cudaq/.local/lib/python3.12/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch) (1.3.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/cudaq/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/cudaq/.local/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/cudaq/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/cudaq/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: galois in /home/cudaq/.local/lib/python3.12/site-packages (0.4.10)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from galois) (2.2.6)\n",
      "Requirement already satisfied: numba>=0.55 in /home/cudaq/.local/lib/python3.12/site-packages (from galois) (0.63.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from galois) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /home/cudaq/.local/lib/python3.12/site-packages (from numba>=0.55->galois) (0.46.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cudaq-qec in /home/cudaq/.local/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: cudaq-qec-cu12==0.5.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cudaq-qec) (0.5.0)\n",
      "Requirement already satisfied: cuda-quantum-cu12>=0.13 in /home/cudaq/.local/lib/python3.12/site-packages (from cudaq-qec-cu12==0.5.0->cudaq-qec) (0.13.0)\n",
      "Requirement already satisfied: astpretty~=3.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (3.0.0)\n",
      "Requirement already satisfied: custatevec-cu12~=1.10 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (1.10.1)\n",
      "Requirement already satisfied: cutensornet-cu12~=2.9 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2.9.1)\n",
      "Requirement already satisfied: cudensitymat-cu12~=0.3 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (0.3.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (1.17.0)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2.32.5)\n",
      "Requirement already satisfied: nvidia-cublas-cu12~=12.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12~=10.3 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12~=12.5 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12~=12.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12~=11.4 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12~=12.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (12.8.93)\n",
      "Requirement already satisfied: cupy-cuda12x~=13.6.0 in /home/cudaq/.local/lib/python3.12/site-packages (from cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (13.6.0)\n",
      "Requirement already satisfied: cutensor-cu12<3,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from cudensitymat-cu12~=0.3->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2.4.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x~=13.6.0->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (0.8.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/cudaq/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12~=11.4->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (12.8.93)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->cuda-quantum-cu12>=0.13->cudaq-qec-cu12==0.5.0->cudaq-qec) (2026.1.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ipywidgets in /home/cudaq/.local/lib/python3.12/site-packages (8.1.8)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (9.9.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/cudaq/.local/lib/python3.12/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/cudaq/.local/lib/python3.12/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/dist-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "New libraries have been installed. Please restart your kernel!\n"
     ]
    }
   ],
   "source": [
    "# install `torch`, 'scikit-learn', 'galois', cudaq-qec' and `ipywidgets` in the current Python kernel. Skip this if they are already installed.\n",
    "# Make sure to restart your kernel if you execute this!\n",
    "# In a Jupyter notebook, go to the menu bar > Kernel > Restart Kernel.\n",
    "# In VSCode, click on the Restart button in the Jupyter toolbar.\n",
    "\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import scikit_learn\n",
    "    import galois\n",
    "    import cudaq_qec\n",
    "    import ipywidgets as widgets\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Tools not found, installing. Please restart your kernel after this is done.\")\n",
    "    !{sys.executable} -m pip install --upgrade pip\n",
    "    !{sys.executable} -m pip install torch\n",
    "    !{sys.executable} -m pip install scikit-learn\n",
    "    !{sys.executable} -m pip install galois\n",
    "    !{sys.executable} -m pip install cudaq-qec\n",
    "    !{sys.executable} -m pip install ipywidgets\n",
    "    print(\"\\nNew libraries have been installed. Please restart your kernel!\")\n",
    "\n",
    "\n",
    "#This lab runs a GPU accelerated decoder and requires access to a GPU\n",
    "import cudaq\n",
    "cudaq.set_target('nvidia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee9745-1d8a-4591-b1c3-0159c4dad662",
   "metadata": {},
   "source": [
    "## 4.1 Decoding Decoded\n",
    "\n",
    "Remember that a QEC round involves four main steps:\n",
    "* Encoding logical qubits and sending the system through a noisy channel, which is often just a duration of time where the qubits are exposed to potential sources of error\n",
    "* Measuring syndrome data\n",
    "* Decoding the syndrome to identify where an error occurred and what instructions to send to the QPU to fix the error\n",
    "* Correcting the error\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/NVIDIA/cuda-q-academic/main/qec101/Images/decoder/decoding.png\" alt=\"Drawing\" style=\"width: 900px;\"/>\n",
    "\n",
    "The decoding step is very challenging and is considered one of the primary limitations for QEC. This is because decoding requires measurements on a QPU, data transfer to the supercomputer, decoding on the supercomputer, and then data transfer back to the QPU.  The time available for this is called the **decoding window** and varies based on a number of factors such as the qubit modality, data transfer rates, and the volume of information that needs to be decoded.\n",
    "\n",
    "The simulation below makes this more clear.  First, set the time for the decoding window. All 50 syndromes must be decoded in this time, otherwise the QEC procedure fails.  In many cases, syndromes vary in decoding difficulty, so this simulation samples random times from a normal distribution.  Try changing the parameters of the distribution and see how this impacts the decoder's success rate.\n",
    "\n",
    "Notice how even if a decoder is quite fast and can decode most of the syndromes in time, the worst-case scenario (i.e. hardest syndrome to decode) is usually the limiting factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397bd4fc-b30a-48ef-be6d-f827ae513b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffa7df9c34a481e8324a2dc0a14dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=50, description='Number of Simulations:', layout=Layout(width='700px'), max=200â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab1392948d843dc89b87b66503ea316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "from Images.decoder.decoder_widget import display_widget\n",
    "display_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13cd03-89fd-4069-a410-36d7047b1d86",
   "metadata": {},
   "source": [
    "Directly competing with speed is accuracy. If a decoder is inaccurate, errors will be missed or introduced each QEC round and will propagate to ruin the computation. High-distance codes are necessary for accuracy, but unfortunately introduce high-qubit overheads and make decoding much more challenging. Advances in QEC code design and low-latency integration between AI supercomputers and QPUs alleviate pressure on the decoding step, but it nevertheless remains the primary bottleneck of QEC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77d598-b3c0-489c-9809-34bdfb7a9a65",
   "metadata": {},
   "source": [
    "## 4.2 Pauli Frames and Error Tracking ##\n",
    "\n",
    "In practice, when errors are identified by the decoder, they are not immediately corrected but are tracked using a Pauli frame. The Pauli frame keeps track of the corrections classically and applies them later. This approach reduces the number of gate operations required to fix errors on the QPU, thereby protecting the encoded state from additional noise introduced by each correction gate. For instance, if a bit flip error occurs on qubit 1 in the first round and another bit flip error happens on the same qubit later, the two errors cancel each other out, eliminating the need for a correction\n",
    "\n",
    "Often, codes are depicted using 3D images like the one below. In this case, each plane is a Steane code QEC round with flagged errors in purple. Each error is saved, and the list grows with future rounds. The final Paul frame, $[X_1, X_5, X_1]$, is the list of corrections for the three bit flip errors that have occurred over all the rounds: two on qubit 1 and one on qubit 5.  In the last step, the errors can be simplified, for example, $X_1X_1 = I$, so only one of the three corrections, $X_5$, needs to be applied. This is a rather trivial example, and often diagrams like this are used to depict more complex codes and their respective error pathways.\n",
    "\n",
    "<img src=\"../Images/decoder/pauliframes.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "The dimension of time can also lend itself to more sophisticated decoding schemes. This is particularly important when measurement errors occur during the stabilizer checks. In this case, it might appear that a stabilizer flags when in fact the data qubits are fine. Multiple decoding rounds can demonstrate that the false stabilizer flag is a consequence of measurement error and not a true error, where other true errors would persist without correction. Such an approach is more powerful but requires decoding of much more complex syndromes. The diagram below demonstrates this concept with an example.\n",
    "\n",
    "<img src=\"../Images/decoder/decodeintime.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "Notice how, in the first case, the decoder has kept track of a measurement error and is therefore making an incorrect syndrome in the final case. When decoding happens over time, the decoding task must not decode a 19-bit syndrome but is able to flag measurement errors\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px;\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0;\"> Exercise  1:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "The benefit of decoding in time is that the measurement errors can be factored into the decoding process.  However, the tradeoff is that the decoding problem is much harder.  When decoding in time, an effective parity check matrix must be constructed as an input to the decoder. In this exercise you will build $H^{(2)}$ for a two round Steane code that includes consistency checks to  flag errors between the two time steps.  \n",
    "\n",
    "First, a few hints.  Consider the dimensions. The number of columns still corresponds to the number of qubits, but, now we need to take into account the data qubits at time 0, the data qubits at time 1, and the three ancilla qubits used to measure syndromes between the two rounds. \n",
    "\n",
    "Each time step will have the same three stabilizer checks, so $H^{(2)}$ should have six rows. \n",
    "\n",
    "The top left block of $H^{(2)}$ and the bottom right block will be $H$, where $H$ is the standard Steane code parity check matrix.\n",
    "\n",
    "What do the middle three columns need to be for $H^{(2)}$ to be able to catch measurement errors?\n",
    "\n",
    "Build $H^{(2)}$, and then build an error vector $e$ of size 17 such that each entry is a 0 or a 1 if an error occurred on that qubit.  Compute $H^{(2)}e^T$ for a case with an error on data qubit 1 in the first time step, an error on data qubit 1 in the second time step only, and a measurement error. Note, it is best practice to assume that the decoder will not hanndle raw syndrome outputs, but the differences between he current set of measurements and the next round.  For example, after preparation the syndrome 101 might be measured. If the next round produces the same stabilizer measurerments, the decoder would see 000 not 101. This syntax makes it much easier for decoders to handle data in more complex settings.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728a78fb-27c7-4f05-9371-77ae7a4884c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0]\n",
      "[1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "H = np.array([\n",
    "    [1, 1, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 1]\n",
    "])\n",
    "\n",
    "#Build 2 round parity check matrix.\n",
    "H2 =  np.array([\n",
    "    [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1]\n",
    "])\n",
    "\n",
    "#Syndrome for no error\n",
    "e = np.array([0,0,0,0,0,0,0, 0,0,0,  0,0,0,0,0,0,0])\n",
    "\n",
    "print(H2 @ e.T)\n",
    "\n",
    "#syndrome for error on first data qubit\n",
    "e = np.array([1,0,0,0,0,0,0, 0,0,0,  0,0,0,0,0,0,0])\n",
    "\n",
    "print(H2 @ e.T)\n",
    "\n",
    "#syndrome for error on first ancilla qubit\n",
    "e = np.array([0,0,0,0,0,0,0, 1,0,0,  0,0,0,0,0,0,0])\n",
    "\n",
    "print(H2 @ e.T)\n",
    "\n",
    "# Notice measurement errors are the only cases where the first three and last three bits of the syndrome disagree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756d468-abdb-4262-b8ee-1540d9cabfa2",
   "metadata": {},
   "source": [
    "Looking at your results. Can you see how a measurement error can be detected in the the symdrome pattern? Note that the parity check matrix you created can only catch measurment errors on round 1.  A round 2 measurement error would be missed unless you extenced the parity check matrix further.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc15193-fe88-49e3-a943-c5188cd0d5d7",
   "metadata": {},
   "source": [
    "## 4.3 Most Likely Error Decoding\n",
    "\n",
    "So far, decoders have been presented as black boxes. In many cases that is sufficient.  If you are developing or testing new codes, you might just use a state of the art decoder and not care how it works.  In other cases, the opposite is true, and you might focus on developing and tuning a decoder to work well for a specific sort of QEC situation. \n",
    "\n",
    "The rest of this lab will allow you to explore a number of different decoders ranging from conceptually simple to state of the art.  You will interact with them in different ways, in certain cases you'll write the decoder from scratch and at other times you'll use the decoder out of the box. \n",
    "\n",
    "The starting point is to consider a naive brute forced decoder that is conceptually simple yet sets the upper bound on decoder accuracy.  \n",
    "\n",
    "The steps of maximum likelihood decoding are as follows (considering only bitflip errors for simplicity):\n",
    "\n",
    "1. Select a QEC code and encode a message in the codespace with $n$ data qubits.\n",
    "2. Generate the $2^n$ bitstrings $\\{x_0, \\cdots, x_{2^n} \\}$ of length $n$ corresponding to all possible error situations.\n",
    "3. For each $x_i$, compute the syndrome as $Hx_i~\\mathrm{mod} 2$ where $H$ is the code's parity check matrix.\n",
    "4. Then, for each possible syndrome, list errors that could have produced the given syndrome.\n",
    "5. Under each syndrome, order errors by their Hamming distance from the original message.\n",
    "6. Finally, the decoder will receive a new syndrome, and then select the lowest Hamming distance error and apply the fix.\n",
    "\n",
    "The assumption here is that, if errors are independent, cases with fewer errors are always more likely than those with more errors. \n",
    "\n",
    "Notice, in Lab 2 when you coded the Steane code, we assumed a situation where one error occurs at a time, allowing your syndrome checks to fix errors.  This is the same assumption made here. The problem with this approach is that it does not scale.  There are $2^n$ errors that need to be computed *a priori* which is not possible for large codes.  The sections below will consider more scaleable heuristics to overcome this issue.\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px;\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0;\"> Exercise  2:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "Code the most likely error decoder for the Steane code below given the parity check matrix below.  For each syndrome, print the associated length 7 bitstrings that produce that error, the Hamming distance from the baseline message (0000000), and the probability of that error.  \n",
    "    </p>\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9771149e-976d-4dbe-aae7-d6aa3e26331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syndrome: (0, 0, 0)\n",
      "  Bitstring: (0, 0, 0, 0, 0, 0, 0), Hamming Weight: 0, Probability: 0.478297\n",
      "  Bitstring: (0, 0, 1, 0, 0, 1, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 0, 0, 1, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 0, 1, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 0, 1, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 1, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 1, 1, 0, 0, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 0, 1, 1, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 0, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 0, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 1, 0, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 1, 1, 0, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 0, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 1, 1, 0, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 1, 1, 1, 1, 1), Hamming Weight: 7, Probability: 0.000000\n",
      "\n",
      "Syndrome: (0, 0, 1)\n",
      "  Bitstring: (0, 0, 0, 0, 0, 0, 1), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 1, 0, 0, 1, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 0, 0, 1, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 0, 0, 1, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 1, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 1, 0, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 1, 0, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 1, 0, 0, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 0, 1, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 0, 0, 1, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 1, 0, 0, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 0, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 0, 1, 1, 0, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 0, 1, 1, 0, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 1, 1, 0), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (0, 1, 0)\n",
      "  Bitstring: (0, 0, 0, 0, 0, 1, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 1, 0, 0, 0, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 0, 1, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 0, 0, 0, 1, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 1, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 0, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 1, 1, 0, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 1, 0, 0, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 0, 0, 1, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 0, 1, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 1, 0, 0, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 0, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 0, 1, 0, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 0, 1, 1, 1, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 1, 0, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (0, 1, 1)\n",
      "  Bitstring: (0, 0, 1, 0, 0, 0, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 0, 0, 0, 1, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 1, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 1, 0, 0, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 0, 0, 1, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 0, 1, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 0, 1, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 1, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 0, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 0, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 1, 0, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 1, 1, 0, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 0, 1, 1, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 0, 0, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 1, 0, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 0, 1, 1, 1, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (1, 0, 0)\n",
      "  Bitstring: (0, 0, 0, 0, 1, 0, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 1, 1, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 0, 0, 0, 0, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 0, 0, 0, 0, 1, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 0, 1, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 0, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 1, 0, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 1, 0, 1, 0, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 0, 1, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 0, 1, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 0, 1, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 1, 0, 1, 0, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 1, 0, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 0, 1, 1, 1, 1, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 0, 0, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 0, 1, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (1, 0, 1)\n",
      "  Bitstring: (0, 1, 0, 0, 0, 0, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 0, 0, 1, 0, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 0, 1, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 0, 1, 0, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 1, 0, 1, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 0, 0, 1, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 0, 1, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 0, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 1, 0, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 0, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 1, 0, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 0, 1, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 0, 1, 0, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 0, 1, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 0, 1, 1, 1, 1, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (1, 1, 0)\n",
      "  Bitstring: (1, 0, 0, 0, 0, 0, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 0, 0, 1, 1, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 1, 0, 0, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 1, 0, 0, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 1, 0, 1, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 0, 0, 0, 1, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 0, 1, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 1, 0, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 1, 1, 1, 0, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 0, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 0, 1, 0, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 0, 1, 1, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 0, 1, 1, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 1, 0, 0, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (0, 1, 1, 1, 1, 1, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n",
      "Syndrome: (1, 1, 1)\n",
      "  Bitstring: (0, 0, 0, 1, 0, 0, 0), Hamming Weight: 1, Probability: 0.053144\n",
      "  Bitstring: (0, 0, 1, 0, 1, 0, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 1, 0, 0, 0, 1, 0), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (1, 0, 0, 0, 0, 0, 1), Hamming Weight: 2, Probability: 0.005905\n",
      "  Bitstring: (0, 0, 0, 0, 1, 1, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 1, 1, 0, 0, 0, 1), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 0, 1, 0, 0, 1, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (1, 1, 0, 0, 1, 0, 0), Hamming Weight: 3, Probability: 0.000656\n",
      "  Bitstring: (0, 0, 1, 1, 0, 1, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 0, 1, 1, 0, 1), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 0, 0, 1, 1, 1, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (1, 1, 1, 1, 0, 0, 0), Hamming Weight: 4, Probability: 0.000073\n",
      "  Bitstring: (0, 1, 1, 1, 1, 1, 0), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 0, 1, 1, 1, 0, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 0, 1, 0, 1, 1), Hamming Weight: 5, Probability: 0.000008\n",
      "  Bitstring: (1, 1, 1, 0, 1, 1, 1), Hamming Weight: 6, Probability: 0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the probability of a bitflip\n",
    "p = 0.1\n",
    "\n",
    "# Define the parity check matrix H\n",
    "H = np.array([\n",
    "    [1, 1, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# Generate all possible length-7 bitstrings\n",
    "bitstrings = list(product([0, 1], repeat=7))\n",
    "\n",
    "# Function to compute Hamming weight\n",
    "def hamming_weight(bitstring):\n",
    "    return sum(bitstring)\n",
    "\n",
    "# Compute H * x % 2 for each bitstring\n",
    "results = []\n",
    "for bitstring in bitstrings:\n",
    "    x = np.array(bitstring).reshape(7, 1)\n",
    "    syndrome = (H @ x) % 2\n",
    "    syndrome = syndrome.flatten()\n",
    "    w = hamming_weight(bitstring)\n",
    "    # Probability of this bitstring given independent flips\n",
    "    prob = (p**w) * ((1 - p)**(7 - w))\n",
    "    results.append((bitstring, syndrome, w, prob))\n",
    "\n",
    "# Sort results based on the syndrome\n",
    "results.sort(key=lambda x: tuple(x[1]))\n",
    "\n",
    "# Organize by syndrome\n",
    "syndrome_dict = {}\n",
    "for bitstring, syndrome, weight, prob in results:\n",
    "    # FIX: Convert numpy types to python ints here\n",
    "    syndrome_tuple = tuple(map(int, syndrome)) \n",
    "    \n",
    "    if syndrome_tuple not in syndrome_dict:\n",
    "        syndrome_dict[syndrome_tuple] = []\n",
    "    syndrome_dict[syndrome_tuple].append((bitstring, weight, prob))\n",
    "\n",
    "# Sort each section by Hamming weight\n",
    "for syndrome in syndrome_dict:\n",
    "    syndrome_dict[syndrome].sort(key=lambda x: x[1])\n",
    "\n",
    "# Print\n",
    "for syndrome, entries in syndrome_dict.items():\n",
    "    print(f\"Syndrome: {syndrome}\") \n",
    "    for bitstring, weight, prob in entries:\n",
    "        print(f\"  Bitstring: {bitstring}, Hamming Weight: {weight}, Probability: {prob:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ead63-c070-4ef7-a097-f01783635be1",
   "metadata": {},
   "source": [
    "## 4.4 AI Decoders\n",
    "\n",
    "One way to circumvent the scaling challenges posed by the a brute force most likely error decoder is to use tools like AI. AI is fantastic at pattern recognition, runs very quickly, and can easily scale. \n",
    "\n",
    "AI decoders also offer flexibility as they can be trained with simulated data or even trained on small-distance codes and, via transfer learning, be used to decode higher distance codes.\n",
    "\n",
    "Recently, [NVIDIA and QuEra announced a new transformed based decoder](https://developer.nvidia.com/blog/nvidia-and-quera-decode-quantum-errors-with-ai/) tested on magic state distillation circuits used by QuEra (A 35 qubit circuit with 5 Steane code logically encoded logical qubits).  The decoder showed promise by outperforming the decoder used by QuEra in terms of speed and accuracy.  Additionally, the AI decoder might have the potential to scale to code distances large enough for sufficiently low logical error rates.\n",
    "\n",
    "<img src=\"../Images/decoder/aidecoderplot.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px;\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0;\"> Exercise  3:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "You will now build a working AI decoder for the Steane code. The goal is to build something similar to the workflow in the image below.\n",
    "\n",
    "<img src=\"../Images/decoder/aidecoderworkflow.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "This lab does not expect you to have experience coding AI models with tools like PyTorch, so you will focus on the data generation and learn how to prepare the data to train an AI decoder without worrying about details of the model. Follow the steps outlined below to complete the code.\n",
    "    </p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc6b5f-e11e-413d-916f-bfad51765298",
   "metadata": {},
   "source": [
    "The first step is to generate the training data. Take the Steane code circuit you coded in Lab 2, now with bitflip noise to each qubit after encoding.  In this case, we can explore circuit-level noise based on simulated results rather than a contrived data set. \n",
    "\n",
    "Create a data set of 1000 samples.  To generate this, run `cudaq.sample()` 2000 times taking one shot each time.  Output the measurements from the syndrome checks (without correcting any errors) and then measure all of the data qubits.  Compute the parity of bits corresponding to the correct logical operator to determine the true logical state.  \n",
    "\n",
    "Save the syndromes and the logical states as two numpy arrays.  This will be your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d407fa45-3f75-46dc-8904-88c2b544cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1], [1, 1, 1], [1, 0, 0], [0, 0, 0], [1, 0, 0], [0, 1, 1], [1, 1, 0], [1, 1, 0], [1, 1, 0], [0, 1, 0]]\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "p = 0.15\n",
    "cudaq.unset_noise()\n",
    "noise = cudaq.NoiseModel()\n",
    "\n",
    "@cudaq.kernel\n",
    "def steane_code() -> list[int]:\n",
    "    \"\"\"Prepares a kernel for the Steane Code\n",
    "    Returns\n",
    "    -------\n",
    "    cudaq.kernel\n",
    "        Kernel for running the Steane code\n",
    "    \"\"\"   \n",
    "    data_qubits = cudaq.qvector(7)\n",
    "    ancilla_qubits = cudaq.qvector(3)\n",
    "\n",
    "    # Create a superposition over all possible combinations of parity check bits\n",
    "    h(data_qubits[4])\n",
    "    h(data_qubits[5])\n",
    "    h(data_qubits[6])\n",
    "\n",
    "    #Entangle states to enforce constraints of parity check matrix\n",
    "\n",
    "    x.ctrl(data_qubits[0],data_qubits[1])\n",
    "    x.ctrl(data_qubits[0],data_qubits[2])\n",
    "\n",
    "    x.ctrl(data_qubits[4],data_qubits[0])\n",
    "    x.ctrl(data_qubits[4],data_qubits[1])\n",
    "    x.ctrl(data_qubits[4],data_qubits[3])\n",
    "\n",
    "    x.ctrl(data_qubits[5],data_qubits[0])\n",
    "    x.ctrl(data_qubits[5],data_qubits[2])\n",
    "    x.ctrl(data_qubits[5],data_qubits[3])\n",
    "\n",
    "    x.ctrl(data_qubits[6],data_qubits[1])\n",
    "    x.ctrl(data_qubits[6],data_qubits[2])\n",
    "    x.ctrl(data_qubits[6],data_qubits[3])\n",
    "\n",
    "    for j in range(7):\n",
    "        cudaq.apply_noise(cudaq.XError, p, data_qubits[j])\n",
    "\n",
    "    # Detect X errors\n",
    "    h(ancilla_qubits)\n",
    "\n",
    "    z.ctrl(ancilla_qubits[0],data_qubits[0])\n",
    "    z.ctrl(ancilla_qubits[0],data_qubits[1])\n",
    "    z.ctrl(ancilla_qubits[0],data_qubits[3])\n",
    "    z.ctrl(ancilla_qubits[0],data_qubits[4])\n",
    "\n",
    "    z.ctrl(ancilla_qubits[1],data_qubits[0])\n",
    "    z.ctrl(ancilla_qubits[1],data_qubits[2])\n",
    "    z.ctrl(ancilla_qubits[1],data_qubits[3])\n",
    "    z.ctrl(ancilla_qubits[1],data_qubits[5])\n",
    "\n",
    "    z.ctrl(ancilla_qubits[2],data_qubits[1])\n",
    "    z.ctrl(ancilla_qubits[2],data_qubits[2])\n",
    "    z.ctrl(ancilla_qubits[2],data_qubits[3])\n",
    "    z.ctrl(ancilla_qubits[2],data_qubits[6])\n",
    "\n",
    "    h(ancilla_qubits)\n",
    "\n",
    "    d0=mz(data_qubits[0])\n",
    "    d1=mz(data_qubits[1])\n",
    "    d2=mz(data_qubits[2])\n",
    "    d3=mz(data_qubits[3])\n",
    "    d4=mz(data_qubits[4])\n",
    "    d5=mz(data_qubits[5])\n",
    "    d6=mz(data_qubits[6])\n",
    "    a0=mz(ancilla_qubits[0])\n",
    "    a1=mz(ancilla_qubits[1])\n",
    "    a2=mz(ancilla_qubits[2])\n",
    "\n",
    "    return [d0,d1,d2,d3,d4,d5,d6,a0,a1,a2]\n",
    "\n",
    "# Generate Data\n",
    "nsamples = 10000\n",
    "syndromes = []\n",
    "logical_flips =[]\n",
    "\n",
    "samples = cudaq.run(steane_code, noise_model=noise, shots_count=nsamples)\n",
    "\n",
    "for samp in samples:\n",
    "    ancilla = [samp[7], samp[8], samp[9]]\n",
    "    data = [samp[0], samp[1], samp[2],samp[3],samp[4],samp[5],samp[6]]\n",
    "    syndromes.append(ancilla)\n",
    "    parity = sum(data) %2\n",
    "    logical_flips.append(parity)\n",
    "\n",
    "\n",
    "print(syndromes[0:10])\n",
    "print(logical_flips[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de27f6f-d427-4592-b341-edfc1eeb4e08",
   "metadata": {},
   "source": [
    "Your data set will be split into a 2000 point training set and a 400 point test set to validate that the model worked.  The inputs to the model will be syndrome data obtained from your simulations.  The loss function will be a comparison between the predicted logical state of the model and the logical state you obtained from measuring the data qubits. \n",
    "\n",
    "If you defined the arrays properly, the code below should preprocesses the data for you, splitting it into a training and test set, construct a simple neural network, define model setting, and train the model.\n",
    "\n",
    "Each epoch is one trining loop through the entire data set.  The model will then test the accuracy using the test set which was excluded from training at each epoch. The code is provided for the interested reader to see the details of the torch implementation, can also just be run as a black box. Do the plots below indicate the model improved as training progressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab77b304-0126-4e91-b324-94a3718a9e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5/30 | train loss=0.5229 | test acc=0.7325\n",
      "Epoch  10/30 | train loss=0.4795 | test acc=0.7650\n",
      "Epoch  15/30 | train loss=0.4706 | test acc=0.7650\n",
      "Epoch  20/30 | train loss=0.4689 | test acc=0.7650\n",
      "Epoch  25/30 | train loss=0.4686 | test acc=0.7650\n",
      "Epoch  30/30 | train loss=0.4685 | test acc=0.7650\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Final Test Accuracy: 0.7650\n",
      "Final Training Loss: 0.4685\n",
      "\n",
      "First 20 test examples:\n",
      "========================================\n",
      "Index  |  True  | Predicted\n",
      "========================================\n",
      "  0    |   0    |   1   \n",
      "  1    |   0    |   0   \n",
      "  2    |   0    |   0   \n",
      "  3    |   1    |   1   \n",
      "  4    |   1    |   1   \n",
      "  5    |   0    |   1   \n",
      "  6    |   0    |   1   \n",
      "  7    |   1    |   1   \n",
      "  8    |   0    |   0   \n",
      "  9    |   0    |   0   \n",
      "  10   |   1    |   0   \n",
      "  11   |   1    |   1   \n",
      "  12   |   0    |   0   \n",
      "  13   |   0    |   0   \n",
      "  14   |   0    |   1   \n",
      "  15   |   0    |   0   \n",
      "  16   |   1    |   1   \n",
      "  17   |   1    |   1   \n",
      "  18   |   0    |   0   \n",
      "  19   |   1    |   1   \n",
      "========================================\n",
      "\n",
      "Accuracy for these 20 examples: 15/20 = 75.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This section normalizes and loads the data you defined previously\n",
    "syndromes = np.array(syndromes, dtype=np.float32)\n",
    "logical_flips = np.array(logical_flips, dtype=np.float32)\n",
    "\n",
    "# Normalize input data\n",
    "syndromes = (syndromes - syndromes.mean()) / syndromes.std()\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    syndromes, logical_flips, test_size=0.20, random_state=42)\n",
    "\n",
    "X_tr = torch.tensor(X_tr)\n",
    "X_te = torch.tensor(X_te)\n",
    "y_tr = torch.tensor(y_tr)\n",
    "y_te = torch.tensor(y_te)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_tr, y_tr),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# This builds a simple NN model which will be trained\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.act(self.fc3(x))\n",
    "\n",
    "model = SimpleDecoder()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "# Define the test_accuracy function\n",
    "def test_accuracy():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = (model(X_te).squeeze() > 0.5).float()\n",
    "        return (pred == y_te).float().mean().item()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30\n",
    "train_losses, test_acc = [], []\n",
    "\n",
    "# epoch 0 (untrained)\n",
    "test_acc.append(test_accuracy())\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Training\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_X).squeeze()\n",
    "        loss = criterion(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    \n",
    "    # Calculate average loss for the epoch\n",
    "    avg_epoch_loss = epoch_loss / batch_count\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    current_acc = test_accuracy()\n",
    "    test_acc.append(current_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_epoch_loss)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:3d}/{num_epochs} | \"\n",
    "              f\"train loss={avg_epoch_loss:.4f} | \"\n",
    "              f\"test acc={current_acc:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(num_epochs + 1), test_acc, marker='o')\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Steane-Code Decoder Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, color='red')\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Final Test Accuracy: {test_acc[-1]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "\n",
    "# Print first 20 predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_te).squeeze()\n",
    "    predicted_labels = (test_predictions > 0.5).float()\n",
    "\n",
    "print(\"\\nFirst 20 test examples:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"{'Index':^6} | {'True':^6} | {'Predicted':^6}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i in range(20):\n",
    "    true_label = int(y_te[i].item())\n",
    "    pred_label = int(predicted_labels[i].item())\n",
    "    print(f\"{i:^6} | {true_label:^6} | {pred_label:^6}\")\n",
    "\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate accuracy for these 20 examples\n",
    "correct = (predicted_labels[:20] == y_te[:20]).sum().item()\n",
    "print(f\"\\nAccuracy for these 20 examples: {correct}/20 = {correct/20:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26973394-04c5-4919-a43e-9ab2d7309fb1",
   "metadata": {},
   "source": [
    "Training AI decoders is a very challenging task and must be used in the proper setting. For example, if the error rate in the training data is very low, The AI model could discover that it can produce pretty good results just by predicting no error each time.  This sort of model does not learn anything about decoding!  Thus, expert care must go into the fine-tuning and validation of AI decoders to ensure they are working properly. The steane code is rather simple and with only $2^7$ possible errors the training data can cover all possible errors. AI decoders in practice can only be trained on a subset of the possible errors, yet must be able to learn enough to decode with high enough accuracy. \n",
    "\n",
    "Also note, that not matter how good the AI decoder is, it cannot overcome the fact that the Steane code is distance three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cb708-3810-43aa-af2e-38144aba2b17",
   "metadata": {},
   "source": [
    "## Belief Propagation Decoding\n",
    "\n",
    "Another state-of-the-art decoding method is belief propagation (BP).  BP is a powerful technique borrowed from classical error correction that is highly flexible and can serve as a black box decoder for arbitrary QEC Codes. It is particularly useful for codes like quantum low-density parity check (qLDPC). All the user needs to do is provide a parity check matrix and then feed the decoder syndromes to decode. \n",
    "\n",
    "NVIDIA created a GPU accelerated BP decoder which allows researchers to push QEC even further than before.  This section will walk you through implementing BP and how to use NVIDIA's accelerated BP decoder. \n",
    "\n",
    "At a high level, BP works by taking initial beliefs about each data qubit's physical error rate and, using syndrome measurements, iteratively update these beliefs to converge on a solution which provides a likelihood of an error occurring or not.  \n",
    "\n",
    "Though there are different variations of BP, one implementation is the following:\n",
    "1. Initialize a log-likelihood ratio $L_{v_i} = log(\\frac{1-p}{p})$ for each data qubit $v_i$ where $p$ is the physical error rate.  If an error is unlikely, the quantity is positive and increases in magnitude the smaller $p$ is as errors are less likley.\n",
    "   \n",
    "2. $L_{v_i\\rightarrow c_j}$, the message sent from each data qubit to a check qubit, is calculated based on the following equation:  $L_{v\\rightarrow c} = L_i + \\sum_{k \\in N(i)/j} L_{c_k\\rightarrow v_i}$ where $\\sum_{k \\in N(i)/j}$ includes all of the check qubits connected to data qubit $v_i$ excluding check qubit $c_j$. That is, the check qubit is updated with beliefs the variable learned from the *other* check qubits it is connected to.\n",
    "\n",
    "   \n",
    "3. Similarly, $L_{c_j\\rightarrow v_i}$ is computed to compute the messages sent back to the variable qubits using $L_{c_j \\to v_i} = (-1)^{s_j} \\cdot 2 \\cdot \\text{arctanh} \\left( \\prod_{k \\in N(j) \\setminus i} \\tanh \\left( \\frac{L_{v_k \\to c_j}}{2} \\right) \\right)$ where $N(j) \\setminus i$ is all *other* variable nodes connected to $c_j$ excluding $v_i$ and $s_j$ is the value of the syndrome measurement for $c_j$.\n",
    "   \n",
    "4. Finally, the final beliefs $L_{\\text{final}, i}$ are computed as $L_i + \\sum_{j \\in N(i)} L_{c_j \\to v_i}$, summing the prior beliefs with the final messages sent to each variable node. From this a decision can be made where positive numbers indicate no error and negative an error, with the magnitudes related to confidence.\n",
    "\n",
    "Ideally, BP will converge to a solution that agrees with the original syndrome and correct the error.  If BP cannot converge, it means there is still significant uncertainty whether some of the bits have errors or not and postprocessing is necessary to refine the result.  This will be discussed in the following section.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px;\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0;\"> Exercise  4:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "Below is the start of a BP implementation for decoding the 5-qubit repetition code. Fill in the sections marked \"TODO\" to complete the code.  Most of the BP loops are calculated for you.  Make sure to review them and understand what is going on.  Then, you will complete the code by fixing the code to calculate the final belief on each qubit and determine where errors occurred.\n",
    "    </p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd605d53-884a-49fb-9e4e-8b9f49e23b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulation Setup ---\n",
      "Physical Error Rate (p): 0.1\n",
      "Actual Error Vector:     [0 0 1 0 0]\n",
      "Resulting Syndrome:      [0 1 1 0]\n",
      "----------------------------------------\n",
      "\n",
      "--- Initialization ---\n",
      "Prior LLR (L_i) for all qubits: 2.1972\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\n",
      "[[2.1972 0.     0.     0.    ]\n",
      " [2.1972 2.1972 0.     0.    ]\n",
      " [0.     2.1972 2.1972 0.    ]\n",
      " [0.     0.     2.1972 2.1972]\n",
      " [0.     0.     0.     2.1972]]\n",
      "\n",
      "Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\n",
      "[[ 2.1972  2.1972  0.      0.      0.    ]\n",
      " [ 0.     -2.1972 -2.1972  0.      0.    ]\n",
      " [ 0.      0.     -2.1972 -2.1972  0.    ]\n",
      " [ 0.      0.      0.      2.1972  2.1972]]\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\n",
      "[[2.1972 0.     0.     0.    ]\n",
      " [0.     4.3944 0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     4.3944 0.    ]\n",
      " [0.     0.     0.     2.1972]]\n",
      "\n",
      "Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\n",
      "[[ 0.      2.1972  0.      0.      0.    ]\n",
      " [ 0.     -0.     -4.3944  0.      0.    ]\n",
      " [ 0.      0.     -4.3944 -0.      0.    ]\n",
      " [ 0.      0.      0.      2.1972  0.    ]]\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\n",
      "[[ 2.1972  0.      0.      0.    ]\n",
      " [ 2.1972  4.3944  0.      0.    ]\n",
      " [ 0.     -2.1972 -2.1972  0.    ]\n",
      " [ 0.      0.      4.3944  2.1972]\n",
      " [ 0.      0.      0.      2.1972]]\n",
      "\n",
      "Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\n",
      "[[ 2.1972  2.1972  0.      0.      0.    ]\n",
      " [ 0.      2.1972 -4.3944  0.      0.    ]\n",
      " [ 0.      0.     -4.3944  2.1972  0.    ]\n",
      " [ 0.      0.      0.      2.1972  2.1972]]\n",
      "\n",
      "--- Iteration 4 ---\n",
      "Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\n",
      "[[ 2.1972  0.      0.      0.    ]\n",
      " [ 4.3944  4.3944  0.      0.    ]\n",
      " [ 0.     -2.1972 -2.1972  0.    ]\n",
      " [ 0.      0.      4.3944  4.3944]\n",
      " [ 0.      0.      0.      2.1972]]\n",
      "\n",
      "Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\n",
      "[[ 4.3944  2.1972  0.      0.      0.    ]\n",
      " [ 0.      2.1972 -4.3944  0.      0.    ]\n",
      " [ 0.      0.     -4.3944  2.1972  0.    ]\n",
      " [ 0.      0.      0.      2.1972  4.3944]]\n",
      "\n",
      "--- Iteration 5 ---\n",
      "Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\n",
      "[[ 2.1972  0.      0.      0.    ]\n",
      " [ 4.3944  4.3944  0.      0.    ]\n",
      " [ 0.     -2.1972 -2.1972  0.    ]\n",
      " [ 0.      0.      4.3944  4.3944]\n",
      " [ 0.      0.      0.      2.1972]]\n",
      "\n",
      "Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\n",
      "[[ 4.3944  2.1972  0.      0.      0.    ]\n",
      " [ 0.      2.1972 -4.3944  0.      0.    ]\n",
      " [ 0.      0.     -4.3944  2.1972  0.    ]\n",
      " [ 0.      0.      0.      2.1972  4.3944]]\n",
      "\n",
      "--- Final Belief ---\n",
      "Final LLRs: [ 6.5917  6.5917 -6.5917  6.5917  6.5917]\n",
      "----------------------------------------\n",
      "Decoder Estimated Error:  [0 0 1 0 0]\n",
      "\n",
      "âœ… Success: The decoder correctly identified the error.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "physical_error_rate = 0.1\n",
    "max_iter = 5\n",
    "\n",
    "H = np.array([\n",
    "    [1, 1, 0, 0, 0],  \n",
    "    [0, 1, 1, 0, 0],  \n",
    "    [0, 0, 1, 1, 0],  \n",
    "    [0, 0, 0, 1, 1]   \n",
    "], dtype=int)\n",
    "\n",
    "n_qubits = H.shape[1]\n",
    "n_checks = H.shape[0]\n",
    "\n",
    "actual_error = np.array([0, 0, 1, 0, 0])\n",
    "\n",
    "syndrome = H @ actual_error % 2\n",
    "\n",
    "print(\"--- Simulation Setup ---\")\n",
    "print(f\"Physical Error Rate (p): {physical_error_rate}\")\n",
    "print(f\"Actual Error Vector:     {actual_error}\")\n",
    "print(f\"Resulting Syndrome:      {syndrome}\")\n",
    "print(\"-\" * 40 + \"\\n\")\n",
    "\n",
    "\n",
    "#Initialize the prior probabilites, and matricies for v -> c and c -> v messages\n",
    "L_prior = np.log((1 - physical_error_rate) / physical_error_rate)\n",
    "\n",
    "L_v_to_c = np.zeros((n_qubits, n_checks))\n",
    "\n",
    "L_c_to_v = np.zeros((n_checks, n_qubits))\n",
    "\n",
    "\n",
    "print(\"--- Initialization ---\")\n",
    "print(f\"Prior LLR (L_i) for all qubits: {L_prior:.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "for iteration in range(max_iter):\n",
    "    print(f\"--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "\n",
    "    # Compute L_{v_i -> c_j} = L_i + sum_{k in N(i)\\j} L_{c_k -> v_i}\n",
    "    # The message is the qubit's own belief (prior) plus all incoming messages from checks\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        for j in range(n_checks):\n",
    "            if H[j, i] == 1:\n",
    "                connected_checks = np.where(H[:, i] == 1)[0]\n",
    "                sum_incoming_L = 0\n",
    "                for k in connected_checks:\n",
    "                    if k != j:\n",
    "                        sum_incoming_L += L_c_to_v[k, i]\n",
    "                L_v_to_c[i, j] = L_prior + sum_incoming_L\n",
    "    \n",
    "    print(\"Step A: Updated Variable-to-Check Message Matrix (L_v_to_c):\")\n",
    "    print(np.round(L_v_to_c, 4))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # TODO: Compute L_{c_j -> v_i} = (-1)^s_j * 2 * atanh( product_{k in N(j)\\i} tanh(L_{v_k -> c_j}/2) )\n",
    "    # The message is based on the check's syndrome value and all of the incoming messages from the data qubits.\n",
    "\n",
    "    for j in range(n_checks):\n",
    "        for i in range(n_qubits):\n",
    "            if H[j, i] == 1:\n",
    "                connected_qubits = np.where(H[j, :] == 1)[0]\n",
    "                prod_tanh = 1.0\n",
    "                for k in connected_qubits:\n",
    "                    if k != i:\n",
    "                        # tanh can be unstable for large LLRs, so we clip its argument\n",
    "                        val = np.clip(L_v_to_c[k, j] / 2, -20, 20)\n",
    "                        prod_tanh *= np.tanh(val)\n",
    "\n",
    "                sign = (-1)**syndrome[j]\n",
    "                \n",
    "                # This defines the missing variable 'prod_tanh_clipped'\n",
    "                epsilon = 1e-12\n",
    "                prod_tanh_clipped = np.clip(prod_tanh, -1 + epsilon, 1 - epsilon)\n",
    "\n",
    "                L_c_to_v[j, i] = sign * 2 * np.arctanh(prod_tanh_clipped)\n",
    "\n",
    "    #END TODO\n",
    "\n",
    "    print(\"Step B: Updated Check-to-Variable Message Matrix (L_c_to_v):\")\n",
    "    print(np.round(L_c_to_v, 4))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "# TODO Compute the final belief of each qubit (prior beliefs plus sum of incoming messages)\n",
    "L_final = np.zeros(n_qubits)\n",
    "for i in range(n_qubits):\n",
    "    connected_checks = np.where(H[:, i] == 1)[0]\n",
    "    sum_final_messages = np.sum(L_c_to_v[connected_checks, i])\n",
    "    L_final[i] = L_prior + sum_final_messages\n",
    "\n",
    "#TODO END\n",
    "\n",
    "print(\"--- Final Belief ---\")\n",
    "print(f\"Final LLRs: {np.round(L_final, 4)}\")\n",
    "\n",
    "\n",
    "estimated_error = (L_final < 0).astype(int)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Decoder Estimated Error:  {estimated_error}\")\n",
    "\n",
    "if np.array_equal(actual_error, estimated_error):\n",
    "    print(\"\\nâœ… Success: The decoder correctly identified the error.\")\n",
    "else:\n",
    "    print(\"\\nâŒ Failure: The decoder did not find the correct error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47decad1-435c-4567-ac20-c9ee839a3665",
   "metadata": {},
   "source": [
    "The 5-qubit repetition code is small, and easy to decode.  If more than one error is present, the BPO decoder will fail, as the code distance is the primary constraint. However, with more complex codes, BP may complete, but not converge, meaning uncertainty remains on some of the bits and a logical error may occur due to its failure. Also, decoding large codes with orders of magnitude more variable and check nodes can become cumbersome. \n",
    "\n",
    "NVIDIA's accelerated BP decoder, now part of the CUDA-Q QEC library, helps address this problem and parallelizes the BP algorithm.  Examining your code above, it is not hard to see how the message calculations can be trivially parallelized, making them well suited for GPU acceleration. \n",
    "\n",
    "Try running NVIDIA's accelerated BP decoder by running the code below which imports a data set of syndrome data from a large qLDPC code.  How long did it take to decode 10 shots?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9fc3d06-186d-4af2-a6b9-0427137b0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bz2\n",
    "import os\n",
    "from Images.decoder.bp import run_decoder, parse_csr_mat, parse_H_csr, parse_obs_csr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # See other test data options in https://github.com/NVIDIA/cudaqx/releases/tag/0.2.0\n",
    "    filename = 'osd_1008_8785_0.001.json' # lower error rate\n",
    "    bz2filename = filename + '.bz2'\n",
    "    if not os.path.exists(filename):\n",
    "        url = f\"https://github.com/NVIDIA/cudaqx/releases/download/0.2.0/{bz2filename}\"\n",
    "        # Download the file\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an error if download fails\n",
    "        with open(bz2filename, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f'Decompressing {bz2filename} into {filename}')\n",
    "\n",
    "        # Decompress the file\n",
    "        with bz2.BZ2File(bz2filename, \"rb\") as f_in, open(filename,\n",
    "                                                          \"wb\") as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "\n",
    "        print(f\"Decompressed file saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f12509-9bff-4618-ace9-ca901e9fbe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your JSON file has 10000 shots. Running 10 now.\n",
      "predicted_observable: [0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "actual_observable:    [0 0 1 1 1 0 1 0 0 0 0 1]\n",
      "predicted_observable: [0 1 1 0 0 0 0 0 1 1 0 0]\n",
      "actual_observable:    [0 1 1 0 0 0 0 0 1 1 0 0]\n",
      "predicted_observable: [1 0 1 1 0 0 0 1 1 1 1 1]\n",
      "actual_observable:    [1 0 1 1 0 0 0 1 1 1 1 1]\n",
      "predicted_observable: [0 1 0 0 0 0 0 0 0 1 1 1]\n",
      "actual_observable:    [0 1 0 0 0 0 0 0 0 1 1 1]\n",
      "predicted_observable: [0 1 0 0 0 1 0 1 0 0 1 1]\n",
      "actual_observable:    [0 1 0 0 0 1 0 1 0 0 1 1]\n",
      "predicted_observable: [0 0 1 0 0 1 0 0 0 1 0 0]\n",
      "actual_observable:    [1 0 1 0 1 1 0 0 0 1 0 0]\n",
      "predicted_observable: [0 0 1 1 1 0 1 1 0 1 0 0]\n",
      "actual_observable:    [0 0 1 1 1 0 1 1 0 1 0 0]\n",
      "predicted_observable: [0 1 1 0 0 1 0 1 0 0 0 1]\n",
      "actual_observable:    [0 1 1 0 0 1 0 1 0 0 0 1]\n",
      "predicted_observable: [0 0 1 1 0 0 0 0 0 1 1 1]\n",
      "actual_observable:    [0 0 1 1 0 0 0 0 0 1 1 1]\n",
      "predicted_observable: [1 0 1 1 0 1 1 1 0 0 1 0]\n",
      "actual_observable:    [1 0 1 1 0 1 1 1 0 0 1 0]\n",
      "1 logical errors in 10 shots\n",
      "Number of shots that converged with BP processing: 9\n",
      "Average decoding time for 10 shots was 2.109861373901367 ms per shot\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10\n",
    "    run_as_batched = True\n",
    "    print_output = True\n",
    "    osd_method = 0 # 0 is off 1 is on\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3d1953-c564-4b9f-9bea-d2b2d6247613",
   "metadata": {},
   "source": [
    "One of the reasons this algorithm can be accelerated is that it can be naturally parallelized. Do you see where that might happen?  \n",
    "\n",
    "The answer lies in the process of sending messages from syndrome qubits to data qubits, and vice versa. Each of these messages can be computed in parallel. This corresponds to performing operations that alternate across the rows and columns of a matrix, depending on which message is being sent. Each row and column can be treated independently, allowing for further parallelization within each row or column.\n",
    "\n",
    "In benchmarks of large code instances, the NVIDIA decoder was up to 35x faster than the industry standard implementation for benchmarks run on the [[144,12,12]](https://arxiv.org/abs/2308.07915) code. \n",
    "\n",
    "<img src=\"../Images/decoder/benchmark.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf56e1-56a3-477d-9048-5c04ec72965a",
   "metadata": {},
   "source": [
    "### Batching\n",
    "\n",
    "The performance can be enhanced ever further using batching.  Batching means that a collection of syndromes are sent to the GPU and decoded simultaneously.  This minimizes data transfer and allows the entire GPU to be working, reducing the average decoding time per shot.  \n",
    "\n",
    "Run the cells below to see the impact of batching when decoding 10000 syndromes. In the second cell, `run_as_batched` is set to `True`. How much faster is batching?  Batching is most effective when decoding a large number of syndromes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dbb6cad-9a72-4a71-b31f-32163142d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your JSON file has 10000 shots. Running 10000 now.\n",
      "287 logical errors in 10000 shots\n",
      "Number of shots that converged with BP processing: 9542\n",
      "Average decoding time for 10000 shots was 1.7048231363296509 ms per shot\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10000\n",
    "    run_as_batched = False\n",
    "    print_output = False\n",
    "    osd_method = 0 # 0 is off 1 is on\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d2432e-3b5f-4c84-b13a-1baf5497ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your JSON file has 10000 shots. Running 10000 now.\n",
      "287 logical errors in 10000 shots\n",
      "Number of shots that converged with BP processing: 9542\n",
      "Average decoding time for 10000 shots was 0.13768088817596436 ms per shot\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10000\n",
    "    run_as_batched = True\n",
    "    print_output = False\n",
    "    osd_method = 0 # 0 is off 1 is on\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535afc57-7053-4c05-aced-4fbfa40c104f",
   "metadata": {},
   "source": [
    "### Ordered Statistics Decoding\n",
    "Now, increase the error rate using a different data file from 0.1 % to 0.5 %.  What happens to the logical error rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5df64203-d885-4ead-aee9-f47f5f91fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bz2\n",
    "import os\n",
    "from Images.decoder.bp import run_decoder, parse_csr_mat, parse_H_csr, parse_obs_csr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # See other test data options in https://github.com/NVIDIA/cudaqx/releases/tag/0.2.0\n",
    "    filename = 'osd_1008_8785_0.005.json' # lower error rate\n",
    "    bz2filename = filename + '.bz2'\n",
    "    if not os.path.exists(filename):\n",
    "        url = f\"https://github.com/NVIDIA/cudaqx/releases/download/0.2.0/{bz2filename}\"\n",
    "        # Download the file\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Raise an error if download fails\n",
    "        with open(bz2filename, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        print(f'Decompressing {bz2filename} into {filename}')\n",
    "\n",
    "        # Decompress the file\n",
    "        with bz2.BZ2File(bz2filename, \"rb\") as f_in, open(filename,\n",
    "                                                          \"wb\") as f_out:\n",
    "            f_out.write(f_in.read())\n",
    "\n",
    "        print(f\"Decompressed file saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bbaf975-e8b2-45fe-b7b2-8de9bd8c8229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your JSON file has 10000 shots. Running 10000 now.\n",
      "7136 logical errors in 10000 shots\n",
      "Number of shots that converged with BP processing: 2169\n",
      "Average decoding time for 10000 shots was 0.29759337902069094 ms per shot\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10000\n",
    "    run_as_batched = True\n",
    "    print_output = False\n",
    "    osd_method = 0 # 0 is off 1 is on\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e1de4-e48f-4bfb-b7a1-739011cafb2b",
   "metadata": {},
   "source": [
    "You should notice a very high logical error rate. Each of these logical error rates is a case where BP could not converge.  Like any numerical solver, it is possible to increase iterations and perform a number of tricks to help BP, but some particularly difficult syndromes will not converge either way. To solve this, BP decoders are often paired with optional ordered statistics decoding (OSD) which performs post-processing to improve the result.  Thus, you might often see a \"BP+OSD\" decoder. \n",
    "\n",
    "The intuition behind OSD decoding is to solve for the errors directly using matrix inversion.  That is, solving $e = H^{-1}s$ where $e$ is a vector with error locations, $s$ is the syndrome, and $H$ is the parity check matrix.  The procedure cannot be performed with the original $H$, so instead, a square matrix with columns of full-rank must be constructed from the columns of $H$. \n",
    "\n",
    "What makes this approach challenging is selecting the right columns.  Many different solutions can be obtained with different column selections, but without guidance, this will likely result in a solution that is not of minimum weight and induce a logical error. Recall, for the most likely error decoder above, that valid errors with high weight are much less likely than low weight errors.  Same idea here, but rather than computing all combinations, the OSD heuristic provides a clever way to search from a really good starting point that is the output of BP. \n",
    "\n",
    "The output of BP assigns a probability of error to each data qubit.  This naturally informs the reordering of the columns to rank from most to least likely to have an error. Next Gaussian elimination is performed on $H$ to determine the first full columns of full rank. These subcolumns are then inverted to get $H^{-1}$ which is multiplied by $s$ to get the error result $e_{[s]}$. The $e_{[s]}$ is then padded with zeros  $e_{[T]} =0$ which results in a total error profile of $ e = (e_{[s]},e_{[T]})$.  \n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #f9fff0; border-left: 6px solid #76b900; padding: 15px; border-radius: 4px;\">\n",
    "    <h3 style=\"color: #76b900; margin-top: 0;\">Exercise 5:</h3>\n",
    "    <p style=\"font-size: 16px; color: #333;\">\n",
    "        The following exercise is based on a <a href=\"https://www.youtube.com/watch?v=b9N2Ps3FTto\" target=\"_blank\" style=\"color: #76b900; text-decoration: underline;\">lecture</a> by Joschka Roffe. Given the parity check matrix below and the probabilities of error from BP. Perform OSD manually and find the error profile that satisfies the syndrome. Note, all computations must be performed using mod 2 arithmetic. This can be accomplished using the <code>galois</code> library which creates a Galois field and allows all <code>numpy</code> operations to compute mod 2.\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73609c4d-25e5-452d-801a-c336cbdf7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Elimination Result\n",
      "[[1 0 0 0 1 1]\n",
      " [0 1 0 0 1 1]\n",
      " [0 0 1 0 0 1]\n",
      " [0 0 0 1 1 0]]\n",
      "Hs 4x4 Matrix\n",
      "[[1 1 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [1 0 1 1]]\n",
      "Error solution for Hs\n",
      "[1 0 0 0]\n",
      "Errors - Padded and Permuted\n",
      "[1 0 0 0 0 0]\n",
      "Errors - Original Ordering\n",
      "[0 0 0 0 1 0]\n",
      "Syndrome\n",
      "[1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import galois\n",
    "\n",
    "\n",
    "GF2 = galois.GF(2)\n",
    "\n",
    "#parity check matrix as numpy array\n",
    "H = np.array([[0, 1, 0, 0, 1, 0],\n",
    "              [0, 0, 1, 0, 0, 1],\n",
    "              [1, 0, 0, 1, 0, 0],\n",
    "              [1, 0, 0, 0, 1, 1]])\n",
    "\n",
    "bp_results = [0.05, 0.5, 0.01, 0.01, 0.82, 0.05]\n",
    "s = GF2([1,0,0,1])\n",
    "\n",
    "# Get indices that would sort bp_results in descending order\n",
    "sorted_indices = sorted(range(len(bp_results)), key=lambda k: bp_results[k], reverse=True)\n",
    "\n",
    "# Rearrange columns of numpy array\n",
    "H_sorted = H[:, sorted_indices]\n",
    "\n",
    "# Convert to GF2 matrix after rearrangement for mod 2 aritmatic\n",
    "GF2 = galois.GF(2)\n",
    "H_sorted = GF2(H_sorted)\n",
    "\n",
    "# Perform Gaussian elimination to identify the first four columns of full rank.\n",
    "def rref(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    r = 0\n",
    "    for c in range(cols):\n",
    "        if r >= rows:\n",
    "            break\n",
    "        if matrix[r, c] == 0:\n",
    "            for i in range(r + 1, rows):\n",
    "                if matrix[i, c] != 0:\n",
    "                    matrix[[r, i]] = matrix[[i, r]]\n",
    "                    break\n",
    "        if matrix[r, c] == 0:\n",
    "            continue\n",
    "        matrix[r] = matrix[r] / matrix[r, c]\n",
    "        for i in range(rows):\n",
    "            if i != r and matrix[i, c] != 0:\n",
    "                matrix[i] = matrix[i] - matrix[i, c] * matrix[r]\n",
    "        r += 1\n",
    "    return matrix\n",
    "\n",
    "print(\"Gaussian Elimination Result\")\n",
    "print(rref(H_sorted.copy())) # First four columns are pivot columns\n",
    "\n",
    "# Build H_s from the first full rank columns\n",
    "Hs = H_sorted[:,:4]\n",
    "print(\"Hs 4x4 Matrix\")\n",
    "print(Hs)\n",
    "\n",
    "# Compute Hs_inverse\n",
    "Hs_inverse = np.linalg.inv(Hs)\n",
    "\n",
    "# Calculate e_s\n",
    "e_s = Hs_inverse @ s.T\n",
    "print(\"Error solution for Hs\")\n",
    "print(e_s)\n",
    "\n",
    "# Pad result with zeros and reorder based on colum sorting from earlier.\n",
    "e = np.pad(e_s, (0, 2), 'constant', constant_values=(0, 0))\n",
    "print(\"Errors - Padded and Permuted\")\n",
    "print(e)\n",
    "\n",
    "\n",
    "e_original = np.zeros_like(e)\n",
    "for i in range(len(e)):\n",
    "    e_original[sorted_indices[i]] = e[i]\n",
    "\n",
    "print(\"Errors - Original Ordering\")\n",
    "print(e_original)\n",
    "\n",
    "# Confirm that the errors produce the expected syndrome from the original H\n",
    "print(\"Syndrome\")\n",
    "print(GF2(H) @ GF2(e_original.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faebcedf-0785-4422-981a-fa8ac9ed09a2",
   "metadata": {},
   "source": [
    "OSD guarantees an error pattern that satisfies the syndrome, but it is not necessarily a minimum weight solution nor avoids a logical error. In the exercise above, you performed OSD-0, or zero order OSD.  To improve results, higher order OSD can be performed.  Higher order OSD performs bitflips in the $e_{[T]}$ bits and checks if a lower weight solution can be found. Generally speaking, the order of the OSD determines how many bitflips are considered, but there is additional nuance not covered here. \n",
    "\n",
    "Lower weight solutions are possible as bit flips in $e_{[T]}$ also impact the other bits in the $e_{[s]}$ subspace. \n",
    "\n",
    "To summarize, syndromes are of varying difficulty. Easy syndromes are solved with BP, OSD-0 is used for moderate syndrome difficulties, and higher order OSD is used for the most challenging.  \n",
    "\n",
    "\n",
    "<img src=\"../Images/decoder/bposd.png\" alt=\"Drawing\" style=\"width: 1000px;\"/>\n",
    "\n",
    "\n",
    "Try running the code below on the 10000 shot data set.  See what happens when `osd_method` is set to 1 for OSD-0.  Then try setting this variable to 3 to run a variant of higher order OSD.  Does the logical error rate improve?  How much more time does it take to perform higher order OSD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebab21-d319-410d-bdc3-a41146eaab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your JSON file has 10000 shots. Running 10000 now.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10000\n",
    "    run_as_batched = True\n",
    "    print_output = False\n",
    "    osd_method = 1  # 0 is off, 1 OSD-0, 3 is OSD-X, where X is the order\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddcc1e9-7bc5-4ead-b9aa-8368095d714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    num_shots = 10000\n",
    "    run_as_batched = True\n",
    "    print_output = False\n",
    "    osd_method = 3 # 0 is off, 1 OSD-0, 3 is a higher order OSD\n",
    "    osd_order = 1\n",
    "    run_decoder(filename, num_shots, run_as_batched, print_output, osd_method, osd_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e66fd-08dc-4ed5-bcf0-00858109baf6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "After completing this notebook, you should now have an understanding for the challenges behind decoding. This begins with the brute force most likely error decoding which is incredibly inefficient. You now have experience using other techniques like AI and BP+OSD decoding to accelerated QEC decoding. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
