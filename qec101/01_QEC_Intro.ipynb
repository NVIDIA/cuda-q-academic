{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead95ce",
   "metadata": {
    "id": "eead95ce"
   },
   "outputs": [],
   "source": [
    "# SPDX-License-Identifier: Apache-2.0 AND CC-BY-NC-4.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135f6e3e-e55f-4b5c-80cb-f8979bba94e0",
   "metadata": {
    "id": "135f6e3e-e55f-4b5c-80cb-f8979bba94e0"
   },
   "source": [
    "# QEC 101 Lab 1 - The Basics of Classical and Quantum Error Correction\n",
    "\n",
    "$\n",
    "\\renewcommand{\\ket}[1]{|{#1}\\rangle}\n",
    "\\renewcommand{\\bra}[1]{\\langle{#1}|}\n",
    "$\n",
    "---\n",
    "## Overview\n",
    "One of the biggest challenges in realizing practical quantum computing is the noisy nature of qubits, making quantum error correction (QEC) essential for detecting and fixing errors in real time. In this lab, youâ€™ll explore the fundamentals of error correction (EC) concepts and terminology, walk through examples of classical EC codes, examine how QEC differs from classical methods, and ultimately get hands-on experience coding your first QEC procedure.\n",
    "\n",
    "**Prerequisites:**\n",
    "Learners should have familiarity with Jupyter notebooks and programming in Python and CUDA-Q.  It is assumed the reader has some familiarity already with quantum computation and is comfortable with braket notation and the concepts of qubits, quantum circuits, measurement, and circuit sampling. The  CUDA-Q Academic course entitled \"[Quick Start to Quantum Computing with CUDA-Q](https://github.com/NVIDIA/cuda-q-academic/tree/main/quick-start-to-quantum)\" provide a walkthrough of this prerequisite knowledge if the reader is new to quantum computing and CUDA-Q or needs refreshing.\n",
    "\n",
    "The list below outlines what you'll be doing in each section of this lab:\n",
    "\n",
    "* **1.1** Define the basics of EC, including the 5 aspects common to EC procedures\n",
    "* **1.2** Code the classical repetition code\n",
    "* **1.3** Code the classical Hamming code\n",
    "* **1.4** Experiment with noisy qubits to understand what makes QEC challenging\n",
    "* **1.5** Explore why there is still hope for QEC\n",
    "* **1.6** Learn the theory for the quantum repetition code\n",
    "* **1.7** Implement the quantum repetition code in CUDA-Q\n",
    "\n",
    "Terminology and notation you'll use\n",
    "* encoder, decoder, logical codewords, codespace, error space, noisy channel, logical error, logical error rate\n",
    "* repetition code, Hamming code, $[n,k,d]$-codes\n",
    "* syndrome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5046650",
   "metadata": {
    "id": "b5046650"
   },
   "source": [
    "Execute the cells below to load all the necessary packages for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f2dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instructions for Google Colab. You can ignore this cell if you have cuda-q set up and have \n",
    "# all the dependent files on your system\n",
    "# Uncomment the lines below and execute the cell to install cuda-q\n",
    "\n",
    "#!pip install cudaq\n",
    "\n",
    "#!wget -q https://github.com/nvidia/cuda-q-academic/archive/refs/heads/main.zip\n",
    "#!unzip -q main.zip\n",
    "#!mv cuda-q-academic-main/qec101/Images ./Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install `qutip` and `ipywidgets` in the current Python kernel. Skip this if they are already installed.\n",
    "# `matplotlib` is required for all visualization tasks.\n",
    "# Make sure to restart your kernel if you execute this!\n",
    "# In a Jupyter notebook, go to the menu bar > Kernel > Restart Kernel.\n",
    "# In VSCode, click on the Restart button in the Jupyter toolbar.\n",
    "\n",
    "# The '\\' before the '>' operator is so that the shell does not misunderstand\n",
    "# the '>' qualifier for the bash pipe operation.\n",
    "\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import qutip\n",
    "    import ipywidgets as widgets\n",
    "    import matplotlib_venn\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Tools not found, installing. Please restart your kernel after this is done.\")\n",
    "    !{sys.executable} -m pip install qutip\\>=5 matplotlib\\>=3.5 matplotlib_venn\n",
    "    !{sys.executable} -m pip install ipywidgets\n",
    "    print(\"\\nNew libraries have been installed. Please restart your kernel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b9c82",
   "metadata": {
    "id": "644b9c82"
   },
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "from cudaq.qis import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Output, VBox, HBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa8e57-2f20-4d1b-a8c1-a8291da83fdc",
   "metadata": {
    "id": "c2fa8e57-2f20-4d1b-a8c1-a8291da83fdc"
   },
   "source": [
    "## 1.1 The Basics of Error Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bcdd8",
   "metadata": {
    "id": "255bcdd8"
   },
   "source": [
    "Classical [Error correction](https://en.wikipedia.org/wiki/Error_correction_code) (EC) is the practice of redundantly encoding data using additional bits such that if some of the data bits are corrupted (flipped from a 0 to a 1 or vice versa) by external noise, the error can be fixed and the integrity of the original data preserved. There are many potential ways to accomplish this and any specific procedure is referred to as an EC code.\n",
    "\n",
    "It is thanks to EC that you can still watch a DVD that has many scratches, enjoy a clear telephone conversation despite the signal becoming noisy after transmission over long distances, or scan a QR code at a restaurant that is partially obscured. Try it yourself. Pull up a QR code and try covering different parts with your hand and notice that your phone can still interpret the link despite obfuscation of some parts of the grid. EC has its limits, but in many cases can essentially eliminate any negative impacts of noise.\n",
    "\n",
    "There are five aspects to any general EC procedure: \n",
    "\n",
    "1. All EC procedures assume there is some initial information that needs to be preserved or transmitted. The sender and recipient need to interact with the same information even if it is stored in different ways throughout an EC procedure.\n",
    "\n",
    "2.  An EC procedure first **encodes** the information across $n$ data bits such that $n$ is larger than the minimum number of bits necessary to store the information. For example, the repitition code that we'll cover in the next section uses 3 bits to encode some binary information stored on a single bit by simply repeating the information stored on the single bit three times.\n",
    "\n",
    "3. The encoding procedure produces **logical codewords** which are the redundant encodings that map to the logical states.  For example, logical 1 could be defined with the codeword 111.\n",
    "\n",
    "4. A logical codeword then proceeds through a **noisy channel**.  A noisy channel has some probability of randomly corrupting (flipping) any of the data bits. \n",
    "\n",
    "5.  The recipient then receives the encoded data and needs to decode it to determine if an error occurred and how they might fix it. Another way to say this, is that the **decoder** takes the message the recipient receives and determines which logical codeword is \"closest\" to it. If the decoder produces the correct logical codeword, the EC procedure worked. If not, a **logical error** occurred and the recipient incorrectly interprets the message - the worst case scenario.\n",
    "\n",
    "No EC procedure is perfect, and is usually benchmarked against **[Shannon's limit](https://en.wikipedia.org/wiki/Noisy-channel_coding_theorem)** which is the theoretical limit of the rate of noise free data transfer that can occur through a channel with a given bandwidth and noise level.\n",
    "\n",
    "In practice, and EC code need to be just \"good enough\" to ensure that errors do not usually impede the target application. Generally speaking, the more redundancy (extra bits) used in the encoding process, the better the EC will be, but this also comes at the cost of more memory and time to perform more sophisticated encoding and decoding. Thus, there is always a tension between the resources available for error correction and the logical error rate of the procedure necessary for a given application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55edc7-6827-4a0b-93ed-199e19ae7a22",
   "metadata": {},
   "source": [
    "## 1.2 The Repetition Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cb846-2e18-4ab1-bf50-800bc7c0abc2",
   "metadata": {},
   "source": [
    "The most basic EC code is called the repetition code. \n",
    "\n",
    "Consider encoding the information in a single bit (0 or 1). The repetition code simply adds more bits which are in the same state. So a 3-bit repetition code encodes the logical 0 state ($0_L$) as 000 and the logical 1 state ($1_L$) as 111, making 000 and 111 the logical codewords.\n",
    "\n",
    "Now, assume $0_L$ is transmitted through a noisy channel such that each data qubit has a probability p=0.1 of flipping erroneously. This means there are eight possible states the encoded message could be in after proceeding through the noisy channel. The states can be sorted into two groups. The space of all logical codewords (000 and 111) is called the **codespace**: \n",
    "\n",
    "| Codespace (as bitstrings)    | Codespace (as logical states)| \n",
    "| ----------- | ----------- | \n",
    "| 000 | $0_L$ |\n",
    "| 111 | $1_L$ |\n",
    "\n",
    "\n",
    "while the rest of all the potentially received messages belong to the **error space** as shown in the table below.\n",
    "\n",
    "The job of the decoder is to map encodings in the error space back to a logical codeword in the codespace.  This is usually done through the help of a calculated property that describes the state called a **syndrome**.  In this case, the syndrome is a majority count of the bits. So, the syndrome of the 101 state would be 2 (the count of how many 1's) and corresponds to logical 1 and the syndrome of 001 would be 1.  Additionally, the syndrome of 111 is 3 and the syndrome of 000 os 0.  So we can apply the decoding rule that a message with a syndrome of 2 or 3 would be decoded as 111, and message with a syndrome of 0 or 1 would be decoded as 000.\n",
    "\n",
    "| Error Space   | Closest logical state to the received message | Error, if only one error occurred in transmission | Syndrome |\n",
    "| ----------- | ----------- | ----------- | ----------- | \n",
    "| 001 | 000 | right most bit | 1| \n",
    "| 010 | 000 | middle bit | 1|\n",
    "| 100 | 000 | left most bit | 1 | \n",
    "| 110 | 111 | right most bit | 2| \n",
    "| 101 | 111 | middle bit |  2 |\n",
    "| 011 | 111 |left most bit | 2 |\n",
    "\n",
    "Any single bit error can be correctly identified and corrected, but two or more bit flips will result in a logical error.  There is no way to know for certain if 110, for example, is a single error from the $1_L$ codeword or two bit errors from the $0_L$ codeword. However, the repetition code still greatly reduces the probability of a logical error compared to no encoding. To be very conservative you could discard results where any error was detected and resend the message.  In this error detection (not correction) case,  a logical error will only occur in the highly unlikely case of three bit flip errors, where 000 was transmitted but 111 was received.  This approach requires additional data transfers to compensate for the cases where errors occurred. Error correction can eliminate the need for extra data transfers at the expense of possibly mistaking a 2-bit error for a 1-bit error.  This hints at an important property of error correction codes: distance.\n",
    "\n",
    "Codes are characterized with the so called [n,k,d] notation where n is the number of data bits used to encode k logical bits and d is the **distance**. The distance is the number of errors that must occur for one logical codeword to become the next closest codeword. In our example of the three bit repetition code $n=3$, $k = 1$, and $d=3$, so we refer to this as a [3,1,3] code. The number of errors a code can correct $t$ is a function of code distance and can be calculated as $t = \\text{floor}[(d-1)/2]$\n",
    "\n",
    "The table below shows the likelihood of the four possible scenarios below. Notice the three bit repetition code with majority count will transmit the message with 0.972 probability of success, a significant improvement over the original probability of 0.9.  The **logical error rate** is equal to $1-p$, where $p$ is the probability of success.  In the case of the 3-bit repetition code, the logical error rate is 0.028.\n",
    "\n",
    "<img src=\"Images/errortable.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "### Exercise  1.1: Coding the Repetition code\n",
    "\n",
    "You now know enough to code up the repetition code. The exercise below will require you to generalize the repetition code so it will work with $n$ bits. Fill in the #TODO sections and then observe the plots that are generated. What conclusions can you draw from the code performance using more bits?  What do you notice about the logical error rate relative to the physical error rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118be65-9328-4a6a-9c94-debb6864cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE 1.1\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def encode(bit, n):\n",
    "    \"\"\"Function that encodes a single bit rendundantly n times\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bit: int\n",
    "        Input bit (1 or 0)\n",
    "    n : int\n",
    "        repetitions to use for encoding\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        string of length n redundantly encoding bit\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "\n",
    "\n",
    "\n",
    "def decode(bits):\n",
    "    \"\"\"Function that decodes a message using majority voting to determine the closest codeword\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bits: str\n",
    "        bitstring corresponding to message that has passed through noisy channel\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        1 or 0 corresponding to decoded codeword\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "\n",
    "\n",
    "\n",
    "def transmit(bits, p_error):\n",
    "    \"\"\"Function that receives a codeword, and randomly flips each bit with probability p_error to emulate transmission through noisy channel\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bits: str\n",
    "        bitstring corresponding to an encoded message without noise\n",
    "    p_error: float\n",
    "        probability that a bit will flip through transmission\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        1 or 0 corresponding to decoded codeword\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "\n",
    "\n",
    "def simulate_logical_error_rate(n, p_error, trials):\n",
    "    \"\"\"Function to determine the logical error rate of an n-bit repetition code over specified number of trials.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        specifies n-bit repetition code to use\n",
    "    p_error: float\n",
    "        probability that a bit will flip through transmission\n",
    "    trials: int\n",
    "        number of trials used to determine logical error rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The logical error rate `n_errors/trials`\n",
    "    \"\"\"   \n",
    "#TODO\n",
    "\n",
    "    \n",
    "\n",
    "def plot_logical_vs_physical_error_rate(n, trials):\n",
    "    \"\"\"Function to plot logical vs physical error rate for fixed n and number of trials.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: int\n",
    "        specifies n-bit repetition code to use\n",
    "    trials: int\n",
    "        number of trials used to determine logical error rate\n",
    "    \"\"\"   \n",
    "\n",
    "    #TODO\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(p_values, logical_error_rates, marker='o')\n",
    "    plt.title('Logical Error Rate vs Physical Error Rate')\n",
    "    plt.xlabel('Physical Error Rate')\n",
    "    plt.ylabel('Logical Error Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot 2: Logical Error Rate vs n \n",
    "def plot_logical_vs_repetitions(p_error, max_n, trials):\n",
    "    \"\"\"Function to plot logical error rate vs bits used for redundant encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    max_n: int\n",
    "        specifies the maximum n-bit repetition code to use\n",
    "    p_error: float\n",
    "        probability that a bit will flip through transmission\n",
    "    trials: int\n",
    "        number of trials used to determine logical error rate\n",
    "    \"\"\"   \n",
    "\n",
    "    #TODO\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(n_values, logical_error_rates, marker='o')\n",
    "    plt.title('Logical Error Rate vs n')\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('Logical Error Rate')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "n = 3         # Number of repetitions for the first plot\n",
    "p_error = 0.1       # Physical error rate for the second plot\n",
    "trials = 10000\n",
    "\n",
    "# Generate the plots\n",
    "plot_logical_vs_physical_error_rate(n, trials)\n",
    "\n",
    "max_n = 20\n",
    "plot_logical_vs_repetitions(p_error, max_n, trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394caa4",
   "metadata": {
    "id": "b394caa4"
   },
   "source": [
    "## 1.3 More Efficient EC Codes (The Hamming Code)\n",
    "\n",
    "There are many clever ways to improve the efficiency of EC codes. One common way is to make use of a concept called **parity checks**. Parity checks provide a clever way to index where errors occur, without a brute force statistical approach like the repetition code. \n",
    "\n",
    "[The Hamming code](https://en.wikipedia.org/wiki/Hamming_code) is a great example of a parity check code.  The [7,4,3] Hamming code consists of four data bits ($d_1, d_2, d_3, d_4$) and three additional parity check bits ($p_1, p_2, p_3$). This example will only consider single bit errors as this is another distance 3 code and can only correct single bit errors. \n",
    "\n",
    "This is accomplished by each parity bit encoding a parity, or the mod2 sum of a subset of the data bits.  The [Venn diagram](https://en.wikipedia.org/wiki/Hamming_code) below depicts the encoding.  In this example, $p_1$ encodes the parity of $d_1$, $d_2$, and $d_4$.  If our data bits ($d_1d_2d_3d_4$) were 0110, then $p_1$ would be calculated to be 1.\n",
    "\n",
    "<img src=\"Images/Hamming(7,4).svg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Either using the static Venn diagram above or the interactive one generated by executing the cell below, \n",
    "reason through the following example:\n",
    "\n",
    "> If you wanted to send the message 0110 (here $d_1 = 0$, $d_2 = 1$, $d_3 = 1$, and $d_4 = 0$), appending the three parity bits to the end of the original bitstring would produce the logical codeword: 0110110 (where $p_1 = 1$, $p_2 = 1$, and $p_3 = 0$).  Note, this is a slight deviation from the traditional placement of the bits in the Hamming code done for simplicity.\n",
    ">\n",
    ">Errors could occur on any of the data or parity bits. Assume an error occurs on $d_2$ and the recipient receives 0010110. To produce the syndrome, the recipient can take the received data bits, 0010, and compute the expected parity. This is then compared to the parity that was sent, 110. The parity bits that disagree flag an error. \n",
    ">\n",
    ">In this case, the received message has parity bits 011 which disagrees with 110. Here, $p_1$ and $p_3$ are flagged.  This syndrome can only correspond to an error on $d_2$ based on the Venn diagram.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b233a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from ipywidgets import VBox, HBox\n",
    "\n",
    "# Function to calculate parity bits\n",
    "def calculate_parity_bits(data_bits):\n",
    "    d1, d2, d3, d4 = data_bits\n",
    "    p1 = d1 ^ d2 ^ d4\n",
    "    p2 = d1 ^ d3 ^ d4\n",
    "    p3 = d2 ^ d3 ^ d4\n",
    "    return [p1, p2, p3]\n",
    "\n",
    "# Function to update the Venn diagram labels based on data bits\n",
    "def update_venn_labels(data_bits):\n",
    "    # Clear the previous output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Clear the computed parity bit outputs\n",
    "    output_p1.clear_output()\n",
    "    output_p2.clear_output()\n",
    "    output_p3.clear_output()\n",
    "\n",
    "    # Display the widgets again\n",
    "    display(VBox([title, data_bits_widget, HBox([button_p1, button_p2, button_p3], layout=widgets.Layout(justify_content='space-between')), HBox([output_p1, output_p2, output_p3])]))\n",
    "\n",
    "    # Create the Venn diagram\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    venn = venn3(subsets=(1, 1, 1, 1, 1, 1, 1), set_labels=('p1', 'p2', 'p3'))\n",
    "\n",
    "    # Set colors for the circles using NVIDIA color palette\n",
    "    venn.get_patch_by_id('100').set_color('#76B900')  # Green\n",
    "    venn.get_patch_by_id('010').set_color('#7A1FA2')  # Purple\n",
    "    venn.get_patch_by_id('001').set_color('#F9A825')  # Yellow\n",
    "\n",
    "    # Set colors for the intersections\n",
    "    venn.get_patch_by_id('110').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('101').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('011').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('111').set_color('#A3A3A3')  # Light Gray\n",
    "\n",
    "    # Set transparency for the circles\n",
    "    venn.get_patch_by_id('100').set_alpha(0.5)\n",
    "    venn.get_patch_by_id('010').set_alpha(0.5)\n",
    "    venn.get_patch_by_id('001').set_alpha(0.5)\n",
    "\n",
    "    # Label the intersections with data bits\n",
    "    venn.get_label_by_id('100').set_text(f'')\n",
    "    venn.get_label_by_id('010').set_text(f'')\n",
    "    venn.get_label_by_id('001').set_text(f'')\n",
    "    venn.get_label_by_id('110').set_text(f'd1={data_bits[0]}')\n",
    "    venn.get_label_by_id('101').set_text(f'd2={data_bits[1]}')\n",
    "    venn.get_label_by_id('011').set_text(f'd3={data_bits[2]}')\n",
    "    venn.get_label_by_id('111').set_text(f'd4={data_bits[3]}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Function to update the Venn diagram and display the messages\n",
    "def update_venn(data_bits, parity_bit):\n",
    "    parity_bits = calculate_parity_bits(data_bits)\n",
    "\n",
    "    # Clear the previous output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # Display the widgets again\n",
    "    display(VBox([title, data_bits_widget, HBox([button_p1, button_p2, button_p3], layout=widgets.Layout(justify_content='space-between')), HBox([output_p1, output_p2, output_p3])]))\n",
    "\n",
    "    # Create the Venn diagram\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    venn = venn3(subsets=(1, 1, 1, 1, 1, 1, 1), set_labels=('p1', 'p2', 'p3'))\n",
    "\n",
    "    # Set colors for the circles using NVIDIA color palette\n",
    "    venn.get_patch_by_id('100').set_color('#76B900')  # Green\n",
    "    venn.get_patch_by_id('010').set_color('#7A1FA2')  # Purple\n",
    "    venn.get_patch_by_id('001').set_color('#F9A825')  # Yellow\n",
    "\n",
    "    # Set colors for the intersections\n",
    "    venn.get_patch_by_id('110').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('101').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('011').set_color('#A3A3A3')  # Light Gray\n",
    "    venn.get_patch_by_id('111').set_color('#A3A3A3')  # Light Gray\n",
    "\n",
    "\n",
    "    # Set transparency for the circles\n",
    "    venn.get_patch_by_id('100').set_alpha(0.5)\n",
    "    venn.get_patch_by_id('010').set_alpha(0.5)\n",
    "    venn.get_patch_by_id('001').set_alpha(0.5)\n",
    "\n",
    "    # Label the intersections with data bits\n",
    "    venn.get_label_by_id('100').set_text(f'')\n",
    "    venn.get_label_by_id('010').set_text(f'')\n",
    "    venn.get_label_by_id('001').set_text(f'')\n",
    "    venn.get_label_by_id('110').set_text(f'd1={data_bits[0]}')\n",
    "    venn.get_label_by_id('101').set_text(f'd2={data_bits[1]}')\n",
    "    venn.get_label_by_id('011').set_text(f'd3={data_bits[2]}')\n",
    "    venn.get_label_by_id('111').set_text(f'd4={data_bits[3]}')\n",
    "\n",
    "    # Highlight the selected parity bit and relevant data bits\n",
    "    if parity_bit == 'p1':\n",
    "        venn.get_patch_by_id('100').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('100').set_linewidth(5)\n",
    "        venn.get_patch_by_id('110').set_color('#76B900')  # Green\n",
    "        venn.get_patch_by_id('101').set_color('#76B900')  # Green\n",
    "        venn.get_patch_by_id('111').set_color('#76B900')  # Green\n",
    "        venn.get_patch_by_id('110').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('110').set_linewidth(5)\n",
    "        venn.get_patch_by_id('101').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('101').set_linewidth(5)\n",
    "        venn.get_patch_by_id('111').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('111').set_linewidth(5)\n",
    "        output_p1.clear_output()\n",
    "        with output_p1:\n",
    "            display(HTML(f\"<b>p1 = d1 + d2 + d4 (mod 2)=</b> {data_bits[0]} + {data_bits[1]} + {data_bits[3]} (mod 2) = {parity_bits[0]}\"))\n",
    "    elif parity_bit == 'p2':\n",
    "        venn.get_patch_by_id('010').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('010').set_linewidth(5)\n",
    "        venn.get_patch_by_id('110').set_color('#7A1FA2')  # Purple\n",
    "        venn.get_patch_by_id('011').set_color('#7A1FA2')  # Purple\n",
    "        venn.get_patch_by_id('111').set_color('#7A1FA2')  # Purple\n",
    "        venn.get_patch_by_id('110').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('110').set_linewidth(5)\n",
    "        venn.get_patch_by_id('011').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('011').set_linewidth(5)\n",
    "        venn.get_patch_by_id('111').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('111').set_linewidth(5)\n",
    "        output_p2.clear_output()\n",
    "        with output_p2:\n",
    "            display(HTML(f\"<b>p2 = d1 + d3 + d4 (mod 2)=</b> {data_bits[0]} + {data_bits[2]} + {data_bits[3]} (mod 2) = {parity_bits[1]}\"))\n",
    "    elif parity_bit == 'p3':\n",
    "        venn.get_patch_by_id('001').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('001').set_linewidth(5)\n",
    "        venn.get_patch_by_id('101').set_color('#F9A825')  # Yellow\n",
    "        venn.get_patch_by_id('011').set_color('#F9A825')  # Yellow\n",
    "        venn.get_patch_by_id('111').set_color('#F9A825')  # Yellow\n",
    "        venn.get_patch_by_id('101').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('101').set_linewidth(5)\n",
    "        venn.get_patch_by_id('011').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('011').set_linewidth(5)\n",
    "        venn.get_patch_by_id('111').set_edgecolor('black')\n",
    "        venn.get_patch_by_id('111').set_linewidth(5)\n",
    "        output_p3.clear_output()\n",
    "        with output_p3:\n",
    "            display(HTML(f\"<b>p3 = d2 + d3 + d4 (mod 2)=</b> {data_bits[1]} + {data_bits[2]} + {data_bits[3]} (mod 2) = {parity_bits[2]}\"))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create a title widget\n",
    "title = widgets.Label(value=\"Hamming Code Visualization: Computing parity bits (p1, p2, p3)\")\n",
    "\n",
    "\n",
    "# Create widgets for user input\n",
    "data_bits_widget = widgets.Dropdown(\n",
    "    options=['0000', '0001', '0010', '0011', '0100', '0101', '0110', '0111', '1000', '1001', '1010', '1011', '1100', '1101', '1110', '1111'],\n",
    "    value='1001',\n",
    "    description='Data Bits (d1, d2, d3, d4):', style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create buttons for parity bits\n",
    "button_p1 = widgets.Button(description='Compute p1', layout=widgets.Layout(width='150px'), style=widgets.ButtonStyle(button_color='#BBE07F'))  # Green\n",
    "button_p2 = widgets.Button(description='Compute p2', layout=widgets.Layout(width='150px'), style=widgets.ButtonStyle(button_color='#BD8FD1'))  # Purple\n",
    "button_p3 = widgets.Button(description='Compute p3', layout=widgets.Layout(width='150px'), style=widgets.ButtonStyle(button_color='#FCD492'))  # Yellow\n",
    "\n",
    "# Create output areas for parity bit results\n",
    "output_p1 = widgets.Output(layout=widgets.Layout(width='300px'))\n",
    "output_p2 = widgets.Output(layout=widgets.Layout(width='300px'))\n",
    "output_p3 = widgets.Output(layout=widgets.Layout(width='300px'))\n",
    "\n",
    "# Define the button click events\n",
    "def on_button_p1_click(b):\n",
    "    data_bits_list = [int(bit) for bit in data_bits_widget.value]\n",
    "    update_venn(data_bits_list, 'p1')\n",
    "\n",
    "def on_button_p2_click(b):\n",
    "    data_bits_list = [int(bit) for bit in data_bits_widget.value]\n",
    "    update_venn(data_bits_list, 'p2')\n",
    "\n",
    "def on_button_p3_click(b):\n",
    "    data_bits_list = [int(bit) for bit in data_bits_widget.value]\n",
    "    update_venn(data_bits_list, 'p3')\n",
    "\n",
    "button_p1.on_click(on_button_p1_click)\n",
    "button_p2.on_click(on_button_p2_click)\n",
    "button_p3.on_click(on_button_p3_click)\n",
    "\n",
    "# Define the dropdown change event\n",
    "def on_data_bits_change(change):\n",
    "    data_bits_list = [int(bit) for bit in change['new']]\n",
    "    update_venn_labels(data_bits_list)\n",
    "\n",
    "data_bits_widget.observe(on_data_bits_change, names='value')\n",
    "\n",
    "# Display the widgets\n",
    "display(VBox([title, data_bits_widget, HBox([button_p1, button_p2, button_p3], layout=widgets.Layout(justify_content='space-between')), HBox([output_p1, output_p2, output_p3])]))\n",
    "\n",
    "# Initial update of the Venn diagram labels\n",
    "update_venn_labels([int(bit) for bit in data_bits_widget.value])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49dfbd9",
   "metadata": {},
   "source": [
    "The Hamming code takes advantage of the fact that the parity bits can encode up to $2^3 = 8$ syndromes, more than enough to consider the seven possible single bit flip errors that could occur. This means, 4 bits can be encoded with 7 bits which is an improvement over the $n$ to 1 encoding of the repetition code.\n",
    "\n",
    "**Checkpoint:**  Suppose you sent the logical code word 0110110, but the recipient received the message 0110100.  We'll assume that at most only one error occurred.  Would the recipient be able to identify if there was an error?  If so, could they locate the error?  \n",
    "Hint: errors could occur on any of the data or the parity bits.\n",
    "\n",
    "In practice, a large message can be broken into blocks with each block is encoded using the Hamming code.  The code scales much better than the repetition code.  A Hamming code can be produced for any integer $r$ greater than 1, such that the code is characterized as $[2^r-1,2^r -r -1,3]$.  So for a message of size $2^5 -5 -1 = 26$, the Hamming code would require only $2^5-1 =31$ bits while a three bit repetition code would require $26*3 = 78$ bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9129bd4-a100-4061-86dd-e69fde915617",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Matrix form of the Hamming Code ###\n",
    "\n",
    "The Hamming code is commonly constructed with special matrices so a few simple linear algebra operations can encode and decode messages. The next two cells will have you define this matrices and see if you can match the example above.  \n",
    "\n",
    "First, define the generator matrix $G$ such that a dot product between the message and $G$  mod2 performs the valid encoding. Hint: G should be a 4x7 matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5c69d-b07c-4d5c-8511-02ee20fedb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = np.array([0, 1, 1, 0])\n",
    "\n",
    "# The G matrix should properly encode the message when the following calculation is performed\n",
    "G = np.array([\n",
    "#FILL IN G.  \n",
    "])\n",
    "\n",
    "encoded = np.dot(message, G) % 2\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf96f28-8a85-4103-8005-651617aa23aa",
   "metadata": {},
   "source": [
    "Now, define the parity check matrix $H$ such that $Hv \\mod 2$ produces a syndrome, where $v$ is the received message vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68795f-5b03-442d-acc5-10859c13e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "received = np.array([0, 0, 1, 0,1,1,0])\n",
    "print(received)\n",
    "\n",
    "# Define the parity check matrix H which takes a message and determines the syndrome.\n",
    "H = np.array([\n",
    "#FILL IN H\n",
    "])\n",
    "\n",
    "decoded = np.dot(H, recieved) % 2\n",
    "\n",
    "# Should print [0 1 1]\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b601a-b343-46d7-9aa5-5d2f5725637c",
   "metadata": {},
   "source": [
    "## 1.4 What Makes QEC so Hard?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99052e-452d-4cde-8067-ae1c469a7eb9",
   "metadata": {},
   "source": [
    "QEC shares the same goal as classical EC, but comes with a number of unique challenges thanks to the properties of quantum mechanics.  This section will list the primary differences, and the following section will explain how these challenges can be addressed.\n",
    " \n",
    "1.  Continuous Errors - Classical errors are always discrete bit flips. Quantum errors are continuous and can manifest in an infinite number of ways, potentially shifting a qubit's state to any point on the Bloch sphere. For instance, the figure below illustrates many possible errors that affect a qubit starting in the $\\ket{0}$ state. Errors can perturb states incoherently (from environmental effects) or coherently from slight hardware imperfections. This invites the question, \"Does QEC require an infinite amount of resources to correct errors?\"\n",
    "   \n",
    "<img src=\"Images/c_error.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "2. No Cloning - Quantum states cannot be copied. That is to say that the following expression holds:$~\\nexists U \\text{ such that } U(\\ket{\\psi} \\otimes \\ket{\\rho}) =  \\ket{\\psi} \\otimes\\ket{\\psi}$. This means we cannot just send multiple copies of the quantum state through the noisy channel like the classical repetition code. \n",
    "\n",
    "3. Destructive Measurement - In classical EC, the state can be accessed at any time, making decoding much easier. Measuring a quantum state collapses it, making the EC moot if the state is destroyed. Therefore, more clever ways to extract syndromes are required. A secondary consequence of this fact is sampling error.  Even if an algorithm could perform perfectly ensuring no sources of error, many applications require statistical sampling of the resulting state. If we sampled $\\ket{\\psi} = \\alpha\\ket{0} + \\beta\\ket{1}$ the frequency of 0's would be close to $\\alpha^2$ but deviate based on the number of samples per the Central Limit Theorem.\n",
    "\n",
    "4. Scalability - Though scalability is an issue for classical EC, it is far more severe for QEC. Today's noisy intermediate scale quantum devices are very difficult to control, so each additional qubit required for QEC comes at great cost.  Qubits also have short coherence times, so QEC procedures must complete within strict time constraints which gets harder at scale. Finally, the threshold theorem is in play. In classical EC, adding more bits always reduces the logical error rate. This is not true for quantum - physical qubits must have noise below a specific threshold in order for scaling the code to improve the error rates,  otherwise, the results just get worse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbbc72-eec4-475c-be5f-53f42fb47963",
   "metadata": {},
   "source": [
    "## 1.5 There is still hope for QEC!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f8326-0b6b-403a-baa4-dc8cd9602910",
   "metadata": {},
   "source": [
    "The challenges discussed above are daunting but there are many ingenious techniques developed to help circumvent them. That said, practical QEC remains difficult to realize and is an extremely active research field - viewed as one of the most important prerequisites for useful quantum computing.  This section will begin to bridge the gap between classical EC and QEC.\n",
    "\n",
    "\n",
    "### Digitization of errors\n",
    "\n",
    "Errors can perturb states incoherently from environmental effects or coherently from slight hardware imperfections.  While both types of errors can be addressed, weâ€™ll focus on coherent errors first because theyâ€™re often easier to isolate and analyze.\n",
    "\n",
    "For instance, a rotation gate that should be at an angle of $\\frac{\\pi}{16} \\approx 0.196 $ ends up being more like 0.17. This may seem inconsequential, but imperfections like this accumulate and quickly ruin the outcome of a quantum algorithm.  Execute the code block below and use the slider to change the number of rotation gates executed to see how the error can become substantial.  Feel free to experiment with different values for the `angle`, `noisy_angle`, and the rotation axis in the `rotation_kernel`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4384ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4245b45f7814e80a159c01104f1a6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='n:', max=20, min=1), Output()),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_plot(num_rotations)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Angles of rotation of a qubit\n",
    "angle = np.pi / 16 \n",
    "noisy_angle = 0.17 \n",
    "\n",
    "# Kernel to initialize a qubit in the zero ket state and rotate it about the x axis by given angle n times\n",
    "@cudaq.kernel\n",
    "def rotation_kernel(n: int, angle: float):\n",
    "    qubit = cudaq.qubit()\n",
    "    for _ in range(n):\n",
    "        rx(angle, qubit) # CHANGE THE ROTATION AXIS\n",
    "\n",
    "# Function to plot sample results\n",
    "def plot_results(results1, results2):\n",
    "    # Convert the sample results to a dictionary\n",
    "    result_dictionary1 = {k: v for k, v in results1.items()}\n",
    "    result_dictionary2 = {k: v for k, v in results2.items()}\n",
    "    \n",
    "    # Get all unique x-values from both dictionaries\n",
    "    all_keys = set(result_dictionary1.keys()).union(set(result_dictionary2.keys()))\n",
    "    all_keys = sorted(all_keys)\n",
    "\n",
    "    # Convert the dictionary to lists for x and y values\n",
    "    x1 = list(all_keys)\n",
    "    y1 = list(result_dictionary1.values())\n",
    "    y2 = list(result_dictionary2.values())\n",
    "\n",
    "    # Create the combined histogram\n",
    "    bar_width = 0.35\n",
    "    x_indices = range(len(x1))\n",
    "\n",
    "    plt.bar(x_indices, y1, width=bar_width, color='#76B900', label='Noise-Free Results')\n",
    "    plt.bar([i + bar_width for i in x_indices], y2, width=bar_width, color='#484848', label='Noisy Results')\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Comparing sampling results of n applications of a noise-free gate with a noisy version')\n",
    "    plt.xlabel(\"Basis States\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks([i + bar_width / 2 for i in x_indices], x1)\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to update the plot based on the slider value\n",
    "def update_plot(num_rotations):\n",
    "    expected_result = cudaq.sample(rotation_kernel, num_rotations, angle)\n",
    "    noisy_result = cudaq.sample(rotation_kernel, num_rotations, noisy_angle)\n",
    "    plot_results(expected_result, noisy_result)\n",
    "\n",
    "# Create an interactive slider\n",
    "slider = widgets.IntSlider(min=1, max=20, step=1, value=1, description='n:', continuous_update=False)\n",
    "interact(update_plot, num_rotations=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959da618",
   "metadata": {},
   "source": [
    "Among the various coherent errors that can occur on a qubit storing the quantum state $\\ket{\\psi} = \\alpha \\ket{0}+\\beta\\ket{1}$, we will focus on three specific types:\n",
    "* **Bit flip errors** swap a qubit's amplitudes, transforming $\\ket{\\psi}$ to $\\beta\\ket{0}+\\alpha\\ket{1}$.\n",
    "* **Phase flip errors** introduce a sign change in one of the amplitudes, transforming $\\ket{\\psi}$ to $\\alpha\\ket{0}-\\beta\\ket{1}$.\n",
    "* **Combining a bit flip with a phase flip error** swaps amplitudes and applies a sign change, transforming $\\ket{\\psi}$ to $\\beta\\ket{0}-\\alpha\\ket{1}$.\n",
    "\n",
    "Run the cell below to open an interactive tool that allows you to visualize the impact of different error types on various quantum states. Observe how some error types may not alter the state. Why do you think that happens? What patterns can you identify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba829f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to see the interactive widget\n",
    "# Don't concern yourself with the code below this line\n",
    "# Function to update and display the Bloch sphere\n",
    "def update_bloch_sphere(theta, phi, error_type):\n",
    "    alpha = np.cos(theta / 2)\n",
    "    beta = np.sin(theta / 2) * np.exp(1j * phi)\n",
    "    coefficients = [complex(alpha, 0), complex(0, beta)]\n",
    "    error_types = ['Bit Flip', 'Phase Flip', 'Bit & Phase Flip']\n",
    "    @cudaq.kernel\n",
    "    def initial_state_kernel(coefficients: list[complex]):\n",
    "        qubit = cudaq.qvector(coefficients)\n",
    "\n",
    "    @cudaq.kernel\n",
    "    def initial_state_error(coefficients: list[complex], error: int):\n",
    "        qubit = cudaq.qvector(coefficients)\n",
    "        if error == 0 or error == 2:\n",
    "            # bit flip error\n",
    "            x(qubit)\n",
    "        if error == 1 or error == 2:\n",
    "            # phase flip error\n",
    "            z(qubit)\n",
    "\n",
    "    state_no_error = cudaq.get_state(initial_state_kernel, coefficients)\n",
    "    state_with_error = cudaq.get_state(initial_state_error, coefficients, error_type)\n",
    "\n",
    "    blochSphereList = []\n",
    "    # Define a sphere object representing the state of the single qubit\n",
    "    sphere = cudaq.add_to_bloch_sphere(state_no_error)\n",
    "    blochSphereList.append(sphere)\n",
    "    sphere = cudaq.add_to_bloch_sphere(state_with_error)\n",
    "    blochSphereList.append(sphere)\n",
    "\n",
    "    # Create output widgets for the Bloch spheres and text\n",
    "    out1 = Output()\n",
    "    out2 = Output()\n",
    "    text1 = Output()\n",
    "    text2 = Output()\n",
    "\n",
    "    with out1:\n",
    "        cudaq.show([blochSphereList[0]], nrows=1, ncols=1)\n",
    "    with out2:\n",
    "        cudaq.show([blochSphereList[1]], nrows=1, ncols=1)\n",
    "    with text1:\n",
    "        print(f\"|Ïˆ> = cos(Î¸/2)|0âŸ© + e^(iÏ†)sin(Î¸/2)|1âŸ©\")\n",
    "    with text2:\n",
    "        print(\"|ÏˆâŸ© with a \", error_types[error_type], \" error\")\n",
    "\n",
    "    display(VBox([HBox([VBox([text1, out1]), VBox([text2, out2])])]))\n",
    "\n",
    "# Create the interactive widget\n",
    "theta_slider = widgets.FloatSlider(value=np.pi/2, min=0, max=2*np.pi, step=0.01, description='Î¸ (radians):')\n",
    "phi_slider = widgets.FloatSlider(value=0, min=0, max=np.pi, step=0.01, description='Ï† (radians):')\n",
    "error_selector = widgets.Dropdown(options=[('None', -1), ('Bit Flip', 0), ('Phase Flip', 1), ('Bit & Phase Flip', 2)], value=-1, description='Error Type:')\n",
    "\n",
    "interact(update_bloch_sphere, theta=theta_slider, phi=phi_slider, error_type=error_selector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da3273",
   "metadata": {},
   "source": [
    "Once we have identified one of these errors, we can correct it. For instance, if a qubit has undergone a bit flip error, we can correct it by applying an $X$ gate. Similarly, to correct a qubit that has experienced a phase flip error, we simply apply a $Z$ gate. How would you correct a qubit that has been identified as having undergone a bit flip error followed by a phase flip error?  \n",
    "\n",
    "We can address all coherent errors with a key insight: although the Bloch sphere suggests errors can occur through infinitely many possible rotations, all such errors can be broken down into three basic forms &mdash; bit flips, phase flips, or a combination of both bit flips and phase flips.  \n",
    "\n",
    "If you'd like an explanation of why this decomposition works, consult the optional section below. For now, remember that by detecting and correcting these three core error types, we can effectively handle any coherent noise.  \n",
    "\n",
    "> **Optional:** Consider a qubit in the following normalized state.\n",
    "> $$ \\ket{\\psi}  =  \\cos\\frac{\\theta}{2}\\ket{0} + e^{i\\phi}\\sin\\frac{\\theta}{2}\\ket{1} $$\n",
    "> \n",
    ">  Coherent errors can be represented by the application of a Unitary $U(\\delta\\theta,\\delta\\phi)$ which acts on the ideal state and perturbs it.\n",
    ">$$ U(\\delta\\theta,\\delta\\phi)\\ket{\\psi}  =  \\cos\\frac{\\theta +\\delta\\theta}{2}\\ket{0} + e^{i\\phi+\\delta\\phi}\\sin\\frac{\\theta+\\delta\\theta}{2}\\ket{1} $$\n",
    "> Using the fact that the Pauli matrices form a basis for any 2x2 unitary matrix and taking advantage of the identity $Y=iXZ$, the operation can be rewritten as\n",
    "> $$ U(\\delta\\theta,\\delta\\phi) \\ket{\\psi} = \\alpha_II\\ket{\\psi} +\\alpha_X X\\ket{\\psi}+\\alpha_Z Z\\ket{\\psi}+\\alpha_{XZ}XZ\\ket{\\psi}   $$\n",
    "> This means that any coherent error can be **digitized** into X-type bit flip errors ($X \\ket{\\psi} = \\alpha X\\ket{0} + \\beta X\\ket{1} = \\alpha\\ket{1} + \\beta\\ket{0}$), Z-type phase flip errors ($Z\\ket{\\psi} = \\alpha Z\\ket{0} + \\beta Z\\ket{1} = \\alpha\\ket{0} - \\beta\\ket{1}$), or a combination of the two (XZ). This makes correction much more tractable, as there are only three types of errors to consider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddc3f4-6d1e-4ed2-b34c-5018220ef617",
   "metadata": {},
   "source": [
    "### Syndrome Extraction\n",
    "\n",
    "The no cloning principle means quantum states cannot be copied for QEC. We'll need a clever way to extract syndromes from the logical state that does not rely on repetition. But, how is this done without destroying the information that is being protected?\n",
    "\n",
    "The solution involves **stabilizers** which are specially designed operators that act on a logical state without changing it, but still enable us to learn about errors by performing projective measurement of ancilla qubits.  The next notebook in this series will introduce stabilizers with more mathematical rigor, and the example in section 1.6 of this lab will provide a more concrete example of a simple stabilizer in action.\n",
    "\n",
    "### Better QEC codes and AI solutions\n",
    "\n",
    "Finally, overcoming the QEC scaling challenges will require breakthroughs on many fronts. Significant research efforts are targeting discovery of more efficient QEC codes that require fewer qubits.  AI is already showing great promise as a tool to help find new QEC codes, and accelerate decoding. Later notebooks will explore AI for QEC applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82e4b87-2d90-499e-91bc-c4f2af3312eb",
   "metadata": {},
   "source": [
    "## 1.6 The Quantum Repetition Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acb1ef-2e39-46c9-88d6-cdd36214ee69",
   "metadata": {},
   "source": [
    "A quantum state cannot be cloned, but it can be redundantly encoded across additional entangled qubits. Let's start with a generic normalized qubit state $\\ket{\\psi}$:\n",
    "\n",
    "$$\\ket{\\psi} = \\alpha\\ket{0} +\\beta\\ket{1}.$$ \n",
    "\n",
    "The 0 and 1 states can be encoded into a logical state making use of the larger 8-dimensional Hilbert space of three qubits:  \n",
    "\n",
    "$$\\ket{\\psi}_L = \\alpha\\ket{000} +\\beta\\ket{111} = \\alpha\\ket{0}_L +\\beta\\ket{1}_L.$$ \n",
    "\n",
    "Note that this is *not* equivalent to $\\ket{\\psi} \\otimes \\ket{\\psi} \\otimes \\ket{\\psi}$.\n",
    "\n",
    "Consider now the entire Hilbert space spanned by the eight basis states.  The basis states are separated into the logical codewords that make up the codespace:   \n",
    "\n",
    "| Codespace    | Notation for the logical codewords| \n",
    "| ----------- | ----------- | \n",
    "| $\\ket{000}$ | $\\ket{0}_L$ |\n",
    "|$\\ket{111}$ | $\\ket{1}_L$ |\n",
    "\n",
    "and the remaining basis states make up the error space:\n",
    "\n",
    "| Error space | \n",
    "| ----------- | \n",
    "| $\\ket{001}$ | \n",
    "| $\\ket{010}$ |\n",
    "| $\\ket{100}$ |\n",
    "| $\\ket{011}$ |\n",
    "| $\\ket{101}$ |\n",
    "| $\\ket{110}$ |\n",
    "\n",
    "Assume that the state $\\ket{111}$ is transmitted through a noisy channel and becomes $\\ket{011}$?  How might it be decoded to tell which logical codeword it is closest to?  Remember, you cannot simply examine the state and perform a majority count as no information about the state is accessible without some sort of measurement that induces wavefunction collapse.  \n",
    "\n",
    "Consider the operators $Z_1Z_2$ and $Z_2Z_3$.  (Remember that $Z_n$ returns an eigenvalue of +1 if the nth qubit in a ket is a 0 and -1 if it is a 1).  \n",
    "It turns out that these operators have special properties such that the eigenvalues produced when they act on any of the states in the codespace or error space can be extracted with ancilla qubits without disturbing the state.  This means, there is a way to extract parity check information just like the classical Hamming code!\n",
    "\n",
    "Note: Operators with these \"special properties\" are called stabilizers and will be rigorously introduced in the next lab.\n",
    "\n",
    "The details of this extraction process are described shortly, but the implication is that syndromes can be produced from the parity check results and used to identify corrections to the quantum repetition code without destroying the encoded state. Considering only single bit flip errors, the table below shows the possible syndromes, the corresponding errors, and the operation that can be applied to correct the error assuming $\\ket{111}$ is the transmitted message.  \n",
    "\n",
    "| $Z_1Z_2$ Syndrome   | $Z_2Z_3$ Syndrome| Encoded State | Single Bit Flip Correction \n",
    "| ----------- | ----------- | ----------- | ----------- | \n",
    "| 0 | 0 | $\\ket{111}$ | none |\n",
    "| 1 | 0 | $\\ket{011}$ | $X_1$ |\n",
    "| 0 | 1 | $\\ket{110}$ | $X_3$ |\n",
    "| 1 | 1 | $\\ket{101}$ | $X_2$ |\n",
    "\n",
    "\n",
    "Like the classical repetition code, there is no way to know for certain if a 10 syndrome corresponds to a single bit flip error from the $\\ket{111}$ codeword or a two bit flip error from the $\\ket{000}$ codeword.  However, it is always prudent to assume that the case with fewer errors is more likely.\n",
    "\n",
    "The entire quantum circuit for the three qubit repetition code is shown below, where the ancilla qubits are used to compute the $Z_1Z_2$ and $Z_2Z_3$ syndromes.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"Images/repcircuit.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "It is helpful to explore in greater detail how the syndromes can be extracted using the ancilla qubits without disturbing the state.\n",
    "First, consider the initial state of the first ancilla after application of a Hadamard gate and the encoded state after a bit flip has occurred on the first data qubit.\n",
    "\n",
    "$$ \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\ket{011} $$\n",
    "\n",
    "Next, a controlled $Z_1Z_2$ operation is applied to the data qubits resulting in\n",
    "\n",
    "$$ \\frac{1}{\\sqrt{2}}(\\ket{0}\\ket{011} + \\ket{1}Z_1Z_2\\ket{011}), $$\n",
    "\n",
    "followed by an application of the second Hadamard:\n",
    "\n",
    "$$ \\frac{1}{2} ((\\ket{0}+\\ket{1})\\ket{011} + (\\ket{0} -\\ket{1})Z_1Z_2\\ket{011})  =  \\ket{0}(\\frac{1+Z_1Z_2}{2})\\ket{011} + \\ket{1}(\\frac{1-Z_1Z_2}{2})\\ket{011}  .   $$\n",
    "\n",
    "Now, if $Z_1Z_2\\ket{011}$ is evaluated, the result is $-\\ket{011}$ and the entire state simplifies to $\\ket{1}\\ket{011}$ meaning upon measurement, the first ancilla qubit will be measured as 1 with certainty and the data qubits remain undisturbed in the $\\ket{011}$ state:\n",
    "\n",
    "\n",
    "$$ \\ket{0}(\\frac{1+Z_1Z_2}{2})\\ket{011} + \\ket{1}(\\frac{1-Z_1Z_2}{2})\\ket{011}  =   \\ket{0}(\\frac{1+ -1}{2})\\ket{011} + \\ket{1}(\\frac{1--1}{2})\\ket{011}  =   \\ket{1}\\ket{011}.  $$\n",
    "\n",
    "A similar analysis will show that the second ancilla qubit will be measured as 0 with certainty without distubring the data qubits.  Accordoing to the syndrome table, \n",
    "this will trigger an application of the $X$ gate on the first qubit to correct the error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbe2ef-044a-46ae-abf3-26f87ba30a12",
   "metadata": {},
   "source": [
    "## 1.7 Exercise 1.3: Coding the Quantum Repetition Code\n",
    "\n",
    "Now that you understand the quantum repetition code, try to code it using CUDA-Q.  Fill in each of the steps below marked \"#TODO\". CUDA-Q contains a couple of features particularly helpful for building QEC workflows.  First, and already completed for you, is the definition of a custom noise model which produces custom identity operations that can randomly perform bit flips on specific qubits. Second, you can measure the ancilla qubits within the kernel and use the result to perform a correction operation.  The documentation example on [building kernels](https://nvidia.github.io/cuda-quantum/latest/using/examples/building_kernels.html) and [mid-circuit measurement](https://nvidia.github.io/cuda-quantum/latest/examples/python/measuring_kernels.html) may be helpful for this exercise.\n",
    "\n",
    "Try to code all the steps and then sample the kernel to determine the logical error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d662290-b51c-4009-8e7c-d9d5f7df40ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \n",
      "  __global__ : { 0:276 00:468 1:256 }\n",
      "   b0 : { 0:468 1:532 }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cudaq\n",
    "import numpy as np\n",
    "\n",
    "#First, create an empty noise model\n",
    "noise_model = cudaq.NoiseModel()\n",
    "p = 0.1\n",
    "\n",
    "#Build a custom gate which applies the identity operation\n",
    "cudaq.register_operation(\"custom_i\", np.array([1, 0, 0, 1]))\n",
    "\n",
    "#Add a bitflip noise channel to the custom_i gate applied to each qubit\n",
    "noise_model.add_channel(\"custom_i\", [0], cudaq.BitFlipChannel(p))\n",
    "noise_model.add_channel(\"custom_i\", [1], cudaq.BitFlipChannel(p))\n",
    "noise_model.add_channel(\"custom_i\", [2], cudaq.BitFlipChannel(p))\n",
    "\n",
    "@cudaq.kernel\n",
    "def three_qubit_repetition_code():\n",
    "    \"\"\"Prepares a kernel for the 3-bit quantum repetition code\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cudaq.kernel\n",
    "        Kernel for running the 3-bit quantum repetition code\n",
    "          \n",
    "    \"\"\"  \n",
    "\n",
    "    # Create register for data and ancilla qubits\n",
    "    # TODO\n",
    "\n",
    "    # Initialize the logical |1> state as |111>\n",
    "    # TODO\n",
    "\n",
    "    # Apply custom_i to induce random bitflip errors\n",
    "    # TODO\n",
    "    \n",
    "    # Extract Syndromes\n",
    "    # TODO\n",
    " \n",
    "    # Correct errors based on syndromes\n",
    "    # TODO\n",
    "\n",
    "# Run the kernel and observe results\n",
    "# The percent of samples that are 000 corresponds to the logical error rate\n",
    "result = cudaq.sample(three_qubit_repetition_code, noise_model=noise_model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef112ea-492e-4a36-978b-0c1d5f5efa83",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You now have a basic understanding of EC and QEC. The next lab will explore stabilizers in more detail and equip you to code two of the most famous and fundamental QEC codes: the Shor code and the Steane code."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
